{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1b18ca3-a7ef-463b-8cbf-a23572692ac3",
   "metadata": {},
   "source": [
    "# Overall comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7f088f-43a1-4e03-bcb7-e1a0603955a1",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203fec46-62bf-4a52-8b24-7080d460e274",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a194690c-8f5c-4df7-a63d-b4caa6332bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "# alt.renderers.enable('png')\n",
    "from pathlib import Path\n",
    "\n",
    "# loading the data \n",
    "from energyclustering.sampling.preprocessing import DataPreprocessor\n",
    "\n",
    "# preprocessing the yearly info \n",
    "from energyclustering.sampling.preprocessing.info import YearlyInfoPreprocessor\n",
    "\n",
    "# executing the results in parallell \n",
    "from dask.distributed import Client\n",
    "\n",
    "# sampling models \n",
    "from energyclustering.sampling.day_of_year_samplers import RandomBaselineSampler # random day selection baseline\n",
    "from energyclustering.sampling.day_of_year_samplers import DailySamplerFromClusterSampler # to combine daily and yearly sampler\n",
    "from energyclustering.sampling.day_of_year_samplers import GenerateSampleDecorator\n",
    "from energyclustering.sampling.samplers import EnergyvilleDaySelectionBaseline\n",
    "from energyclustering.sampling.samplers import MetadataSampler\n",
    "from energyclustering.sampling.samplers import ConsumptionDataSampler\n",
    "\n",
    "\n",
    "# elbow method to use for clustering \n",
    "from energyclustering.clustering.elbow import ElbowMethod\n",
    "from energyclustering.clustering.preclustering import PreClusteringClusterer # two stage clustering procedure\n",
    "\n",
    "# clustering algorithms \n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from kmedoids import KMedoids\n",
    "from energyclustering.clustering.kmedoids import CustomKMedoids\n",
    "\n",
    "# cluster metrics \n",
    "import energyclustering.clustering.metrics as dist_metrics\n",
    "\n",
    "# classifiers \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "# evaluation \n",
    "from energyclustering.sampling.evaluation import SamplerEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700aecc-c966-442c-b3ec-4520d2edb33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e38d48-6f80-41fb-b46b-59cef9da7196",
   "metadata": {},
   "source": [
    "# The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04710ba2-9e97-4ec0-9bc5-0c9f8d18478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data_df, data_df, daily_info_df, weather_df = (\n",
    "    DataPreprocessor()\n",
    "    .preprocess_info_df('paper')\n",
    "    .preprocess_weather_df('paper')\n",
    "    .drop_days_with_nan(True)\n",
    "    .subsample_days(week_reduction_factor = None)\n",
    "    # for testing only!\n",
    "    .subsample_years(2000)\n",
    "    .get_data()\n",
    ")\n",
    "daily_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fb6b7a-fd88-45c3-ab3a-cce2f9fcc121",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_info_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb7f5ec-5c5a-4795-b7c0-b1a7c93eedac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate folds for cross validation \n",
    "generator = np.random.default_rng(1)\n",
    "shuffled = data_df.index.to_numpy(copy=True)\n",
    "generator.shuffle(shuffled)\n",
    "folds = np.array_split(shuffled, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fd6227-0bb8-461a-aa0b-658e0c1389d3",
   "metadata": {},
   "source": [
    "## Models to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e8c72-d044-449a-969f-7afc17b4385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict()\n",
    "NB_SAMPLES = 250\n",
    "CLUSTER_RANGE = list(range(10, 101, 5))\n",
    "\n",
    "# random baseline \n",
    "models['random_baseline'] = RandomBaselineSampler(NB_SAMPLES)\n",
    "\n",
    "# rule based approach \n",
    "models['rule-based_metadata_clustering'] = (\n",
    "    GenerateSampleDecorator(\n",
    "        sampler = DailySamplerFromClusterSampler(\n",
    "            yearly_sampler = MetadataSampler(\n",
    "                clusterer = ElbowMethod(KMeans(n_clusters = 1, n_init = 10), cluster_range = CLUSTER_RANGE), \n",
    "                info_preprocessing = YearlyInfoPreprocessor(columns_to_use = ['yearly_consumption', 'connection_power'], normalized = True),\n",
    "            ), \n",
    "            daily_sampler = EnergyvilleDaySelectionBaseline()\n",
    "        ), \n",
    "        n_samples = NB_SAMPLES,\n",
    "    )\n",
    ")\n",
    "\n",
    "# consumption clustering based approach \n",
    "models['consumption_clustering'] = (\n",
    "     GenerateSampleDecorator(\n",
    "        sampler = DailySamplerFromClusterSampler(\n",
    "            yearly_sampler = ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(),\n",
    "                clusterer = ElbowMethod(KMedoids(n_clusters = 1, method = 'fasterpam'), metric = dist_metrics.euc_distance_matrix_missing, cluster_range = CLUSTER_RANGE, nb_repeats = 10), \n",
    "#                 clusterer = ElbowMethod(KMeans(n_clusters = 1, n_init = 1), metric = None, cluster_range = CLUSTER_RANGE, nb_repeats = 1), \n",
    "#                 clusterer = KMeans(n_clusters = 5, n_init = 10), \n",
    "                fillna = False,\n",
    "#                 fillna = True,\n",
    "            ), \n",
    "            daily_sampler = ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(),\n",
    "                clusterer = ElbowMethod(\n",
    "                    clusterer = KMeans(n_clusters = 1),\n",
    "                    cluster_range = CLUSTER_RANGE,\n",
    "#                     show_progress = True,\n",
    "                ), \n",
    "#                 clusterer = KMeans(n_clusters = 30, n_init = 1), \n",
    "            ), \n",
    "#             show_progress= True,\n",
    "        ), \n",
    "        n_samples = NB_SAMPLES,\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c0cde-1372-441f-9335-a1fd35a5077b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask_util import get_dask_cluster\n",
    "cluster = get_dask_cluster(\n",
    "    pinac_numbers = [31, 32, 33, 34, 35, 36, 37, 38, 39, 40],\n",
    "    himec_numbers = [8, 1, 2, 3],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5843b9de-f32e-4fa5-8058-8093fe02b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "import dask \n",
    "logging.basicConfig(format='%(asctime)s - %(name)s: %(message)s', level=logging.DEBUG, filename = f'logs/comparison_{datetime.datetime.now().strftime(\"%d-%m-%Y\")}.log', filemode = 'w')\n",
    "dask.config.set({'distributed.comm.retry.count': 5, 'distributed.comm.retry.delay.min': '20s', 'distributed.comm.retry.delay.max': '60s'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da50d5a9-859a-4b18-a890-2ded9b983eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "result_path = Path()/'results'/'comparison_5fold_2000'\n",
    "result_path.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "energy_scores = []\n",
    "with Client(cluster) as client:\n",
    "    evaluator = SamplerEvaluator(folds, daily_data_df, daily_info_df, data_df, client, 400, crossval = True)\n",
    "    for key, model in list(models.items()):\n",
    "        energy_score = evaluator.evaluate_and_save(model, result_path/f\"{key}.pkl\")\n",
    "        energy_scores.append(energy_score)\n",
    "    energy_scores = pd.concat(energy_scores, axis = 1, keys = models.keys())\n",
    "\n",
    "# aggregate energy scores\n",
    "plot_df = energy_scores.agg(['mean', 'std'], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0517ba1-9337-4085-96f6-51adcf1705b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6240293c-253c-40ff-ac56-6c783b6abfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_df = plot_df.T.reset_index().replace({\"random_baseline\" : 'Random sampling', \"rule-based_metadata_clustering\" : \"Expert-based\", \"consumption_clustering\" : \"Data-driven\"}).set_axis(['Method', 'Mean ES', 'Std ES'], axis = 1)\n",
    "alt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246fd06c-1ad7-48f3-a370-45c43ab2700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chart_util import big_chart\n",
    "chart = alt.Chart(alt_df, height = 80).mark_bar(size = 20).encode(\n",
    "    y = alt.Y(\"Method:N\", title = None, axis = alt.Axis(domain = False, ticks = False), sort = ['Random Baseline', 'Metadata Clustering', 'Consumption Clustering']), \n",
    "    x = alt.X('Mean ES', title = 'Mean ES (lower is better)'), \n",
    "    color = alt.Color('Method:O', legend = None),\n",
    ")\n",
    "text_chart = alt.Chart(alt_df, height = 80).mark_text(align = 'left', size = 14, dx = 5).encode(\n",
    "    y = alt.Y(\"Method:N\", title = None, axis = alt.Axis(domain = False, ticks = False), sort = ['Random Baseline', 'Metadata Clustering', 'Consumption Clustering']), \n",
    "    x = alt.X('Mean ES', title = 'Mean ES (lower is better)'), \n",
    "    text = alt.Text(\"Mean ES\",format = '.3f'),\n",
    "    # color = alt.Color('Method:O', legend = None),\n",
    ")\n",
    "big_chart(chart + text_chart, fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50be59c1-c428-4312-8b20-d899a7f98bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_df = energy_scores.set_axis(['Random', 'Metadata Clustering', 'Consumption Clustering'], axis = 1).reset_index(drop = True).stack().to_frame('value').rename_axis(['index', 'method'], axis = 0).reset_index()\n",
    "alt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf1a7c0-ef74-4525-a7e6-5d1229475e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d7143-c2a7-4987-b34e-25e1ce334074",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = alt.Chart(alt_df, width = 1000).mark_boxplot().encode(\n",
    "    y = alt.Y(\"method:N\", title = None, axis = alt.Axis(domain = False, ticks = False)), \n",
    "    x = alt.X('value', title = 'ES (lower is better)'), \n",
    "    color = alt.Color('method:O', legend = None),\n",
    ").interactive(bind_y = False)\n",
    "big_chart(chart, fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb4a696-1252-4eef-b956-758313e74508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energyville",
   "language": "python",
   "name": "energyville"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
