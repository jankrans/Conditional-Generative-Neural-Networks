{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc5a52a-c81d-4554-a3f7-120870129cdd",
   "metadata": {},
   "source": [
    "# Influence of #clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b74c9bb-bccf-440f-9300-984bafa40fda",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dfc2f4-223a-4371-9d74-b832f1b9728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "# loading the data \n",
    "from energyclustering.sampling.preprocessing import DataPreprocessor\n",
    "\n",
    "# preprocessing the yearly info \n",
    "from energyclustering.sampling.preprocessing.info import YearlyInfoPreprocessor\n",
    "\n",
    "# executing the results in parallell \n",
    "from dask.distributed import Client\n",
    "\n",
    "# sampling models \n",
    "from energyclustering.sampling.day_of_year_samplers import RandomBaselineSampler # random day selection baseline\n",
    "from energyclustering.sampling.day_of_year_samplers import DailySamplerFromClusterSampler # to combine daily and yearly sampler\n",
    "from energyclustering.sampling.day_of_year_samplers import GenerateSampleDecorator\n",
    "from energyclustering.sampling.day_of_year_samplers import EnergyFilterFromRandomYearSampler # to use energyfilter from a random year\n",
    "from energyclustering.sampling.samplers import RandomSamplerBaseline\n",
    "from energyclustering.sampling.samplers import EnergyvilleDaySelectionBaseline\n",
    "from energyclustering.sampling.samplers import MetadataSampler\n",
    "from energyclustering.sampling.samplers import ConsumptionDataSampler\n",
    "\n",
    "\n",
    "# elbow method to use for clustering \n",
    "from energyclustering.clustering.elbow import ElbowMethod\n",
    "\n",
    "# clustering algorithms \n",
    "from sklearn.cluster import KMeans\n",
    "from kmedoids import KMedoids\n",
    "\n",
    "# cluster metrics \n",
    "import energyclustering.clustering.metrics as dist_metrics\n",
    "from energyclustering.clustering.kmedoids import CustomKMedoids\n",
    "\n",
    "# classifiers \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "# evaluation \n",
    "from energyclustering.sampling.evaluation import SamplerEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7db867c-d50f-4353-a813-0995621ea79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c7b799-c957-438b-81d7-39136a472b58",
   "metadata": {},
   "source": [
    "# The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b3720e-d08a-4fa7-9bae-1888279f596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data_df, data_df, daily_info_df, weather_df = (\n",
    "    DataPreprocessor()\n",
    "    .preprocess_info_df('paper')\n",
    "    .preprocess_weather_df('paper')\n",
    "    .drop_days_with_nan(True)\n",
    "    .subsample_days(week_reduction_factor = None)\n",
    "    # for testing only!\n",
    "    .subsample_years(1000)\n",
    "    .get_data()\n",
    ")\n",
    "daily_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16553b99-727d-440e-9924-12c498f04f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate folds for cross validation \n",
    "generator = np.random.default_rng(1)\n",
    "shuffled = data_df.index.to_numpy(copy=True)\n",
    "generator.shuffle(shuffled)\n",
    "folds = np.array_split(shuffled, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb0d56e-d7ce-4e0a-a615-6ec287c5a469",
   "metadata": {},
   "source": [
    "## Models to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dec2d6-f55c-4f4d-9aba-53b8420a1b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_SAMPLES = 250\n",
    "CLUSTER_RANGE = [1] + list(range(10, 101, 10))\n",
    "CLUSTER_RANGE_ALGORITHM = list(range(10, 101, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7d9572-a9e8-4ba3-83dd-0a425285dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict()\n",
    "for NB_CLUSTERS in CLUSTER_RANGE: \n",
    "    models[f'yearly_clusters={NB_CLUSTERS}'] =  GenerateSampleDecorator(\n",
    "        sampler = DailySamplerFromClusterSampler(\n",
    "            yearly_sampler = ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(),\n",
    "                clusterer = CustomKMedoids(n_clusters = NB_CLUSTERS, metric = dist_metrics.euc_distance_matrix_missing), \n",
    "                fillna = False,\n",
    "            ), \n",
    "            daily_sampler = EnergyvilleDaySelectionBaseline(),\n",
    "        ), \n",
    "        n_samples = NB_SAMPLES,\n",
    "    )\n",
    "    models[f'daily_clusters={NB_CLUSTERS}'] =  GenerateSampleDecorator(\n",
    "        sampler = DailySamplerFromClusterSampler(\n",
    "                yearly_sampler = ConsumptionDataSampler(\n",
    "                    classifier = RandomForestClassifier(),\n",
    "                    clusterer = ElbowMethod(KMedoids(n_clusters = 1, method = 'fasterpam'), metric = dist_metrics.euc_distance_matrix_missing, cluster_range = CLUSTER_RANGE_ALGORITHM, nb_repeats = 10), \n",
    "                    fillna = False,\n",
    "                ), \n",
    "                daily_sampler =  ConsumptionDataSampler(\n",
    "                    classifier = RandomForestClassifier(),\n",
    "                    clusterer = KMeans(n_clusters = NB_CLUSTERS),\n",
    "                ),\n",
    "        ), \n",
    "        n_samples = NB_SAMPLES,\n",
    "    )\n",
    "        \n",
    "models['consumption_clustering'] = (\n",
    "     GenerateSampleDecorator(\n",
    "        sampler = DailySamplerFromClusterSampler(\n",
    "            yearly_sampler = ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(),\n",
    "                clusterer = ElbowMethod(KMedoids(n_clusters = 1, method = 'fasterpam'), metric = dist_metrics.euc_distance_matrix_missing, cluster_range = CLUSTER_RANGE_ALGORITHM, nb_repeats = 10), \n",
    "#                 clusterer = ElbowMethod(KMeans(n_clusters = 1, n_init = 1), metric = None, cluster_range = CLUSTER_RANGE, nb_repeats = 1), \n",
    "#                 clusterer = KMeans(n_clusters = 5, n_init = 10), \n",
    "                fillna = False,\n",
    "#                 fillna = True,\n",
    "            ), \n",
    "            daily_sampler = ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(),\n",
    "                clusterer = ElbowMethod(\n",
    "                    clusterer = KMeans(n_clusters = 1),\n",
    "                    cluster_range = CLUSTER_RANGE_ALGORITHM,\n",
    "#                     show_progress = True,\n",
    "                ), \n",
    "#                 clusterer = KMeans(n_clusters = 30, n_init = 1), \n",
    "            ), \n",
    "#             show_progress= True,\n",
    "        ), \n",
    "        n_samples = NB_SAMPLES,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b584a3-deb5-430b-9d1a-42663a54f5fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask_util import get_dask_cluster\n",
    "cluster = get_dask_cluster(\n",
    "    pinac_numbers = [31, 32, 33, 34, 35, 36, 37, 38, 39, 40],\n",
    "    himec_numbers = [8,1, 2],\n",
    ")\n",
    "# cluster = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4f19c5-59e3-4422-8df7-27d73e46db0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "import dask \n",
    "logging.basicConfig(format='%(asctime)s - %(name)s: %(message)s', level=logging.DEBUG, filename = f'logs/number_of_clusters_{datetime.datetime.now().strftime(\"%d-%m-%Y\")}.log', filemode = 'w')\n",
    "dask.config.set({'distributed.comm.retry.count': 5, 'distributed.comm.retry.delay.min': '60s', 'distributed.comm.retry.delay.max': '100s'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd43aa26-5af8-4785-a390-49297116fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "result_path = Path()/'results'/'nb_of_clusters'\n",
    "result_path.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "energy_scores = []\n",
    "with Client(cluster) as client:\n",
    "    evaluator = SamplerEvaluator(folds, daily_data_df, daily_info_df, data_df, client, 400, crossval = True)\n",
    "    for key, model in models.items():\n",
    "        energy_score = evaluator.evaluate_and_save(model, result_path/f\"{key}.pkl\")\n",
    "        energy_scores.append(energy_score)\n",
    "    energy_scores = pd.concat(energy_scores, axis = 1, keys = models.keys())\n",
    "\n",
    "cluster.close()\n",
    "# aggregate energy scores\n",
    "plot_df = energy_scores.agg(['mean', 'std'], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c2007c-c68e-4bc8-84c5-1def23ca7f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy_scores = pd.concat(energy_scores, axis = 1, keys = models.keys())\n",
    "plot_df = energy_scores.agg(['mean', 'std'], axis = 0)\n",
    "plot_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca70ce0-99c4-48a1-8e49-3373d9ea033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal = plot_df.loc['mean', 'consumption_clustering']\n",
    "optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bad3005-77ee-4e26-9832-485f77c556e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df= plot_df.drop(columns = ['consumption_clustering']).T['mean'].to_frame('ES').assign(\n",
    "    nb_clusters = lambda x: list(map(lambda x: int(x[1]), x.index.str.split('='))), \n",
    "    cluster_type = lambda x: list(map(lambda x: x[0], x.index.str.split('=')))\n",
    ")\n",
    "plot_df.set_index(['cluster_type', 'nb_clusters']).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb0527a-f1fc-4d4e-bb02-693247347f73",
   "metadata": {},
   "source": [
    "### Optimal yearly clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb30cd3-29ec-4a75-9e58-e0af1bbfa6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = plot_df.set_index(['cluster_type', 'nb_clusters']).sort_index()\n",
    "df.loc['yearly_clusters'].sort_values('ES')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466c599d-b845-4853-8767-4b8e919a0fd1",
   "metadata": {},
   "source": [
    "### Optimal daily clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b97597c-28bc-4fad-a421-90bde0ab6864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = plot_df.set_index(['cluster_type', 'nb_clusters']).sort_index()\n",
    "df.loc['daily_clusters'].sort_values('ES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d05a80-955d-432d-af16-6172cd5bc866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02357e6-8016-43f5-b58a-ae531bcad83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chart_util import big_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d47168-c473-4fdf-9b28-8569d3ad8e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = plot_df[plot_df.nb_clusters == 100].copy()\n",
    "text_df.loc[:, 'ES'] +=  [-0.005, +0.005]\n",
    "text_chart = alt.Chart(text_df).mark_text( align = 'left', dx = 10, fontSize = 20).encode(\n",
    "       x = 'nb_clusters', \n",
    "    y = 'ES:Q',\n",
    "    color = 'cluster_type',\n",
    "    text = 'cluster_type'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ada36f-affc-4b9d-870b-f1b2628ee1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c3df0a-5cba-4e10-bd2c-f81a876c5cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = alt.Chart(plot_df, width = 500).mark_line(size = 3).encode(\n",
    "    x = alt.X('nb_clusters:Q', title = '#Clusters'),\n",
    "    y = alt.Y('ES:Q', title = 'average ES (lower is better)',  scale = alt.Scale(zero = False)), \n",
    "    color = 'cluster_type',\n",
    ")\n",
    "big_chart(chart + text_chart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3784ccf9-ead8-42e5-8cc7-28f6ef0b858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_chart(chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f049714f-b645-4b43-a30c-f3c154024fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_plot = alt.Chart(plot_df[plot_df.cluster_type == 'yearly_clusters']).mark_line().encode(\n",
    "       x = 'nb_clusters:Q', \n",
    "    y = alt.Y('ES', title = 'mean ES (lower is better)', scale = alt.Scale(zero = False)),\n",
    ")\n",
    "optimal_line = alt.Chart(pd.DataFrame([30], columns = ['nb_clusters'])).mark_rule().encode(\n",
    "        x = 'nb_clusters:Q'\n",
    ")\n",
    "text = optimal_line.mark_text(angle = 270, baseline = 'bottom', fontSize = 20).encode(\n",
    "    text = alt.TextValue('selected #clusters')\n",
    ")\n",
    "year_chart = (year_plot + optimal_line + text).resolve_scale(x = 'shared', y= 'shared')\n",
    "big_chart(year_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0c51be-dd68-4154-83b2-aa92fd2ee014",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_plot = alt.Chart(plot_df[plot_df.cluster_type == 'daily_clusters']).mark_line().encode(\n",
    "       x = 'nb_clusters:Q', \n",
    "    y = alt.Y('ES', title = 'mean ES (lower is better)', scale = alt.Scale(zero = False)),\n",
    ")\n",
    "optimal_line = alt.Chart(pd.DataFrame([optimal], columns = ['ES'])).mark_rule().encode(\n",
    "    y = 'ES',\n",
    ")\n",
    "text = optimal_line.mark_text(baseline = 'bottom', fontSize = 20).encode(\n",
    "    text = alt.TextValue('adaptive #clusters')\n",
    ")\n",
    "day_chart = (day_plot + optimal_line + text).resolve_scale(x = 'shared', y = 'shared')\n",
    "big_chart(day_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d362498e-6201-4de9-a777-bf83986d04d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_chart((year_chart.properties(title = 'yearlong clustering') | day_chart.properties(title = 'daylong clustering')).resolve_scale(x = 'shared', y = 'shared'), fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7f8c7d-93c1-472c-b4d4-34d59b4a6f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338ff5ea-d99c-4b6a-96d8-e5d8a1b2cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cac962a-b130-4d14-aab3-8603e97848ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energyville",
   "language": "python",
   "name": "energyville"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
