{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dbf537-cf9a-4eda-a487-a365ac2be293",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21800da-8e92-42ab-8a7f-8c4a8a834c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b47b484-484e-4bc8-8643-70a8e8275ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from energyclustering.sampling.preprocessing import DataPreprocessor\n",
    "from dask.distributed import Client\n",
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7106864-764a-48f3-b80c-2aeb8fd19a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1273a1-b156-4b77-b038-bb3d5fb01ddb",
   "metadata": {},
   "source": [
    "# The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ba7d8a-794e-4090-902f-18dd18d92b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data_df, data_df, daily_info_df, weather_df = (\n",
    "    DataPreprocessor()\n",
    "    .preprocess_info_df('baseline')\n",
    "    .preprocess_weather_df('baseline')\n",
    "    .drop_days_with_nan(True)\n",
    "    # no subsampling this time\n",
    "    .subsample_days(week_reduction_factor = None)\n",
    "    # for testing only!\n",
    "    .subsample_years(500)\n",
    "    .get_data()\n",
    ")\n",
    "household_info = daily_info_df.loc[:, 'household_info'].droplevel('date').pipe(lambda x: x[~x.index.duplicated(keep = 'first')])\n",
    "daily_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c02a822-e67a-4ec9-a5f0-c2b40f1b6c22",
   "metadata": {},
   "source": [
    "# Clustering algoritms and distance matrices \n",
    "After some experimentation I figured out the following things: \n",
    "- clustering using dtw distances becomes unfeaseable for large numbers of instances and clusters \n",
    "    - Calculating a single dtw distance $O(4l)$ (linear because of the warping constraint) \n",
    "    - KMedoids: needs the complete distance matrix\n",
    "    - KMedoids BUT there is a fast implementation called FasterPAM which is really fast! (implemented in rust) \n",
    "    - KMeans w. barycentric averaging \n",
    "    - Spectral clustering: also an option BUT also limited in number of instances \n",
    "- clustering with euclidean distances is a lot easier for large number of instances and clusters \n",
    "    - KMeans and KMedoids run a lot faster, but with an increasing number of clusters they become more expensive to run as well (even parallellized) \n",
    "    - DBSCAN is fast but works based on a radius, which is difficult to define in this case. + it is connectivity based, which is not what we want here!\n",
    "    - BIRCH would have been an option, but this has a dependence on the number of features which is 96 in our case! (sklearn proposes a practical limit of 20 features)\n",
    "    - MiniBatchKMeans seems a good option, it runs really fast but only finds an approximate solution (although that should not be too bad for us) \n",
    "    \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b102e3cb-e6ff-45b3-a9d0-f7cc602b6e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtaidistance import dtw, clustering\n",
    "import time\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from tqdm import tqdm\n",
    "import kmedoids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388f5ae1-bcc4-4d70-82d2-67dd96a26f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmedoids_dtw(data, n_clusters): # very slow compared to kmedoids_fast_dtw\n",
    "    model = clustering.KMedoids(dtw.distance_matrix_fast,  {\"window\": 4},max_it = 10, k=n_clusters, show_progress = False)\n",
    "    cluster_idx = model.fit(data)\n",
    "    return cluster_idx \n",
    "\n",
    "def kmeans_dba(data, n_clusters):  \n",
    "    model = clustering.KMeans(k=n_clusters, max_it=10, max_dba_it=10, dists_options={\"window\": 4}, show_progress = False)\n",
    "    cluster_idx, performed_it = model.fit(data, use_c=True, use_parallel=True)\n",
    "    return cluster_idx\n",
    "\n",
    "def kmeans_euc(data, n_clusters): \n",
    "    model = KMeans( n_clusters=n_clusters)\n",
    "    model.fit(data)\n",
    "    return model.labels_\n",
    "\n",
    "def kmedoids_fast_euc(data, n_clusters): \n",
    "    km = kmedoids.KMedoids(n_clusters, method='fasterpam')\n",
    "    matrix = euclidean_distances(data)\n",
    "    c = km.fit(matrix)\n",
    "    return c.labels_\n",
    "\n",
    "def kmedoids_fast_dtw(data, n_clusters): \n",
    "    matrix = dtw.distance_matrix_fast(data, window = 4)\n",
    "    km = kmedoids.KMedoids(n_clusters, method = 'fasterpam') \n",
    "    c = km.fit(matrix)\n",
    "    return c.labels_\n",
    "\n",
    "def minibatchkmeans(data, n_clusters): \n",
    "    model = MiniBatchKMeans( n_clusters=n_clusters, batch_size = 256*40)\n",
    "    model.fit(data)\n",
    "    return model.labels_\n",
    "\n",
    "all_algorithms = {a.__name__: a for a in [kmeans_dba, kmeans_euc, kmedoids_fast_euc, kmedoids_fast_dtw, minibatchkmeans]}\n",
    "fast_algorithms = {a.__name__: a for a in [kmeans_euc, kmedoids_fast_euc, kmedoids_fast_dtw, minibatchkmeans]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4b57e4-3fdb-49f1-aab1-a50e7dd9fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtime_experiment(sizes, n_clusters, clustering_algorithms): \n",
    "    timings = pd.DataFrame(index = pd.MultiIndex.from_product([sizes, n_clusters]), columns = clustering_algorithms.keys())\n",
    "    hfig = display(timings, display_id=True)\n",
    "    for size in sizes: \n",
    "        days = daily_data_df.sample(size, random_state = 0, replace = True).to_numpy()\n",
    "        for k in n_clusters: \n",
    "            for algo_name, cluster in clustering_algorithms.items(): \n",
    "                start_time = time.time()\n",
    "                labels = cluster(days, k)\n",
    "                end_time = time.time() - start_time\n",
    "                timings.loc[(size, k), algo_name] = end_time \n",
    "                hfig.update(timings)\n",
    "    return timings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaedfe2-d470-40fd-a988-3eee787a297a",
   "metadata": {},
   "source": [
    "# all algorithms some slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e8a69e-43eb-4a1c-b423-2947c59b2364",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_experiment(np.logspace(8, 12, num = 3, base = 2, dtype = 'int'), [100], all_algorithms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45618ee3-5b88-4344-8dc6-f33e681a1521",
   "metadata": {},
   "source": [
    "# fast algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f90399-b9b5-4e07-b9ad-706bf02d6401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime_experiment(np.logspace(11, 20, num = 8, base = 2, dtype = 'int'), [500, 1000, 2000], fast_algorithms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd334348-340a-4eda-952c-dc59a7aa739d",
   "metadata": {},
   "source": [
    "## Two step clustering\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a4237b-5eb3-42f8-a047-78c2cab5de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from energyclustering.clustering.preclustering import PreClusteringClusterer\n",
    "\n",
    "euc_distance_matrix = lambda x: euclidean_distances(x)\n",
    "class CustomKMedoids: \n",
    "    def __init__(self, nb_clusters, metric, random_state = None): \n",
    "        self.nb_clusters = nb_clusters\n",
    "        self.metric = metric\n",
    "        self.random_state = random_state\n",
    "        self.labels_ = None\n",
    "    \n",
    "    def fit(self, data):\n",
    "        matrix = self.metric(data) \n",
    "        km = kmedoids.KMedoids(self.nb_clusters, method = 'fasterpam', random_state = self.random_state) \n",
    "        c = km.fit(matrix)\n",
    "        self.labels_ = c.labels_.astype('int')\n",
    "        return self\n",
    "clusterer = PreClusteringClusterer(\n",
    "        pre_clusterer = MiniBatchKMeans(n_clusters = 5000, batch_size = 40*300), \n",
    "        post_clusterer = CustomKMedoids(40, euc_distance_matrix, random_state = 0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a83ad61-6d15-4158-b6b3-1c669b375ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clusterer.fit(daily_data_df.sample(300*365).to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9be0fa4-1d73-469e-8953-76bc159dfa27",
   "metadata": {},
   "source": [
    "# Check whether dtw distances help in classification \n",
    "We test kmeans, minibatchkmeans, kmedoids and kmedoids_dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cec1d68-149c-4a4c-b351-3a10462e0f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from energyclustering.sampling.inspection.classificationinspection import ClassificationInspection\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bd6d01-aeed-4597-b678-28d1e6354b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = np.random.default_rng(1)\n",
    "shuffled = data_df.index.to_numpy(copy=True)\n",
    "generator.shuffle(shuffled)\n",
    "folds = np.array_split(shuffled, 3)\n",
    "train_set = np.concatenate((folds[0],folds[1]))\n",
    "test_set = folds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b69193-6491-4324-960c-ef2cf72e3f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_exp(clusterer, data_to_use, data_to_plot = None):\n",
    "    global inspect\n",
    "    inspect = ClassificationInspection(clusterer, RandomForestClassifier(), data_to_use, daily_info_df.loc[:, 'day_info'], train_set, test_set).fit_model()\n",
    "    if data_to_plot is None:\n",
    "        inspect.data = daily_data_df\n",
    "    else: \n",
    "        inspect.data = data_to_plot\n",
    "    \n",
    "    display(inspect.training_cluster_size_df().T)\n",
    "#     display(inspect.confusion_matrix(sort_by_size = True))\n",
    "    display(inspect.classification_performance())\n",
    "    display(inspect.plot_clustering_line(sample = 25))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f447dc-e902-498a-9340-15d2312635e2",
   "metadata": {},
   "source": [
    "## Do a yearly clustering first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e49d3-d986-4b9a-9efe-6d75f242db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = euclidean_distances(data_df.fillna(0))\n",
    "matrix = pd.DataFrame(matrix, index = data_df.index)\n",
    "inspect = ClassificationInspection(kmedoids.KMedoids(10, method='fasterpam', random_state = 0), RandomForestClassifier(), matrix,household_info, train_set, test_set).fit_model()\n",
    "inspect.data = data_df\n",
    "display(inspect.cluster_size_df().T)\n",
    "inspect.plot_yearly_clustering_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a03df-4e81-4419-9c80-534997a68d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_to_plot = inspect.clustering.pipe(lambda x: x[x == 0]).index\n",
    "profiles_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2cc823-b114-49d0-b99a-c705f8b37a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data_df_subset = daily_data_df.loc[profiles_to_plot]\n",
    "daily_data_df_subset\n",
    "shuffled = daily_data_df_subset.index.get_level_values(0).unique().to_numpy(copy = True)\n",
    "generator.shuffle(shuffled)\n",
    "folds = np.array_split(shuffled, 3)\n",
    "train_set = np.concatenate((folds[0],folds[1]))\n",
    "test_set = folds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a42b2c0-11a0-4a12-a5fe-d179e08e14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CLUSTERS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eefa8f7-dd6d-43d4-815d-fda61b30709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_exp(KMeans(n_clusters = NB_CLUSTERS), daily_data_df_subset, daily_data_df_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadfba6b-e6c0-4eb4-a763-8251bcb551ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = dtw.distance_matrix_fast(daily_data_df_subset.to_numpy(), window = 4)\n",
    "matrix = pd.DataFrame(matrix, index = daily_data_df_subset.index)\n",
    "\n",
    "accuracy_exp(kmedoids.KMedoids(NB_CLUSTERS, method ='fasterpam') , matrix, daily_data_df_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0fc026-47de-490d-a9a3-805320bb414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = euclidean_distances(daily_data_df_subset.to_numpy())\n",
    "matrix = pd.DataFrame(matrix, index = daily_data_df_subset.index)\n",
    "\n",
    "accuracy_exp(kmedoids.KMedoids(NB_CLUSTERS, method = 'fasterpam') , matrix, daily_data_df_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7048e24c-1633-4483-aea6-12e29827b0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energyville",
   "language": "python",
   "name": "energyville"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
