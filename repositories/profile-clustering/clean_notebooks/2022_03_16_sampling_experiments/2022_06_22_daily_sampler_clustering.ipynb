{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ac01d-16e7-4ae8-bf9d-3a4419c07060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0507f06-1300-4c4f-b41b-d84c4d798624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from energyclustering.sampling.preprocessing import DataPreprocessor\n",
    "from energyclustering.sampling.inspection.consumptionclustering import ConsumptionClusteringInspector\n",
    "from dask.distributed import Client\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from energyclustering.sampling.samplers import ConsumptionDataSampler, MetadataSampler, EnergyvilleDaySelectionBaseline, RandomSamplerBaseline\n",
    "from energyclustering.sampling.day_of_year_samplers import DailySamplerFromClusterSampler, GenerateSampleDecorator\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from pathlib import Path\n",
    "from energyclustering.sampling.evaluation.evaluation import SamplerEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55156fc-3c62-4ca7-bcee-c9e35817d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from energyclustering.sampling.inspection.classificationinspection import ClassificationInspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91003308-2e60-4bae-9790-51a99056f5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f51be-afae-4b5f-9d69-ca8a6a81b728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f63090-bf80-4b3b-bb21-593aa5bc6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5cb493-8eb7-4c40-84db-99f6ec5d60fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599786c0-e155-430c-964e-1011b3022c26",
   "metadata": {},
   "source": [
    "# The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5adf9f4-4006-4bd4-a9c6-e7c11bbb1529",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data_df, data_df, daily_info_df, weather_df = (\n",
    "    DataPreprocessor()\n",
    "    .preprocess_info_df('baseline')\n",
    "    .preprocess_weather_df('baseline')\n",
    "    .drop_days_with_nan(True)\n",
    "    # no subsampling this time\n",
    "    .subsample_days(week_reduction_factor = None)\n",
    "    # for testing only!\n",
    "    .subsample_years(1000)\n",
    "    .get_data()\n",
    ")\n",
    "household_info = daily_info_df.loc[:, 'household_info'].droplevel('date').pipe(lambda x: x[~x.index.duplicated(keep = 'first')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de7eb40-8826-4894-b06c-9243b0530e2d",
   "metadata": {},
   "source": [
    "# Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf21b356-cfd1-457e-ab25-2ddc7cc8aa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = np.random.default_rng(1)\n",
    "shuffled = data_df.index.to_numpy(copy=True)\n",
    "generator.shuffle(shuffled)\n",
    "folds = np.array_split(shuffled, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3845ec22-01a2-4cd4-9f42-f7578fd3d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.concatenate((folds[0],folds[1]))\n",
    "test_set = folds[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b85598-4b44-4739-ba6b-9f544c2b8479",
   "metadata": {},
   "source": [
    "## Custom metric for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d889ca-127a-468d-95e9-bee2070b4db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric\n",
    "from pyclustering.utils.metric import type_metric, distance_metric;\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "from pyclustering.cluster.kmeans import kmeans\n",
    "from energyclustering.clustering.clusterers import MyKMedoids, PrecomputedClustering, PrecomputedDistanceMetricClustering\n",
    "from pyclustering.cluster.kmedoids import kmedoids\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from numba import jit, float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2858ce0-8ff3-41ed-a5f5-03f1bb8d00f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@jit(float64(float64[:], float64[:]), nogil = True, nopython = True)\n",
    "def dist(a1, a2): \n",
    "    return np.nanmean((a1-a2)**2)\n",
    "custom_metric = distance_metric(type_metric.USER_DEFINED, func = dist)\n",
    "\n",
    "custom_distance_matrix = pairwise_distances(data_df.to_numpy(), metric = dist, n_jobs = -1, force_all_finite = False)\n",
    "custom_distance_matrix = pd.DataFrame(custom_distance_matrix, index = data_df.index, columns = data_df.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df7e68f-89ba-4a33-aaf6-f303dec48d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomKMeans: \n",
    "    def __init__(self, nb_clusters, random_state = None): \n",
    "        self.nb_clusters = nb_clusters\n",
    "    \n",
    "    def fit(self, data): \n",
    "        # initialize initial centers using K-Means++ method\n",
    "        initial_centers = kmeans_plusplus_initializer(data, self.nb_clusters).initialize()\n",
    "        # create instance of K-Means algorithm with prepared centers\n",
    "        kmeans_instance = kmeans(data, initial_centers, metric = custom_metric)\n",
    "        # run cluster analysis and obtain results\n",
    "        kmeans_instance.process()\n",
    "        labels = np.zeros(data.shape[0])\n",
    "        for cluster_idx, instance_indices in enumerate(kmeans_instance.get_clusters()): \n",
    "            labels[instance_indices] = cluster_idx\n",
    "        self.labels_ = labels.astype('int')\n",
    "        return self\n",
    "    \n",
    "    \n",
    "class CustomKMedoids: \n",
    "    def __init__(self, nb_clusters, random_state = None): \n",
    "        self.nb_clusters = nb_clusters\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit(self, data): \n",
    "        # initialize initial medoids at random\n",
    "        generator = np.random.default_rng(self.random_state)\n",
    "        initial_medoids = generator.choice(data.shape[0], size=self.nb_clusters, replace=False)\n",
    "        # create instance of K-Means algorithm with prepared centers\n",
    "        kmeans_instance = kmedoids(data.to_numpy(), initial_medoids, data_type='distance_matrix')\n",
    "        # run cluster analysis and obtain results\n",
    "        kmeans_instance.process()\n",
    "        labels = np.zeros(data.shape[0])\n",
    "        for cluster_idx, instance_indices in enumerate(kmeans_instance.get_clusters()): \n",
    "            labels[instance_indices] = cluster_idx\n",
    "        self.labels_ = labels.astype('int')\n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26527511-5365-42df-b3cb-01896ba77ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect(yearly_clusterer, daily_clusterer, yearly_data_to_use, daily_data_to_use, min_cluster_size = 10): \n",
    "    global inspector\n",
    "    inspect = ClassificationInspection(yearly_clusterer, RandomForestClassifier(), yearly_data_to_use, household_info, train_set, test_set).fit_model()\n",
    "    display(inspect.training_cluster_size_df().T)\n",
    "    clusters_to_investigate = inspect.training_cluster_size_df().pipe(lambda x: x[x['#items'] > min_cluster_size]).index\n",
    "    for cluster_idx in clusters_to_investigate: \n",
    "        instances_in_cluster = inspect.clustering.pipe(lambda x: x[x == cluster_idx]).index\n",
    "        test_instances_in_cluster = instances_in_cluster.intersection(test_set)\n",
    "        train_instances_in_cluster = instances_in_cluster.intersection(train_set)\n",
    "        daily_data = daily_data_to_use.loc[instances_in_cluster]\n",
    "        day_info = daily_info_df.loc[instances_in_cluster, 'day_info']\n",
    "        inspector = ClassificationInspection(daily_clusterer, DecisionTreeClassifier(min_samples_leaf = 25, max_depth = 4, min_impurity_decrease = 0.01), daily_data, day_info, train_instances_in_cluster, test_instances_in_cluster)\n",
    "        inspector = inspector.fit_model()\n",
    "        display(HTML(f'<h1>cluster {cluster_idx}, #items {len(instances_in_cluster)}</h1>'))\n",
    "        inspector.plot_clustering_line(sample = 500)\n",
    "        display(inspector.training_cluster_size_df().T)\n",
    "        display(inspector.confusion_matrix(sort_by_size = True))\n",
    "        inspector.plot_tree()\n",
    "        display(inspector.classification_performance())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fd3f6b-7f66-4b33-8483-d398079950c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect(KMeans(100), KMeans(20), data_df.fillna(0), daily_data_df, min_cluster_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4ef88-6d7e-49cd-8eda-76c1361dd934",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect(CustomKMedoids(40), KMedoids(20), custom_distance_matrix, daily_data_df.fillna(0), min_cluster_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1681c0bf-bddf-45e4-bc89-c078a108ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WASSER = 'full_distance_matrix_wasserstein'\n",
    "directory = Path('/cw/dtaiproj/ml/2020-FLAIR-VITO/profile-clustering/distance_matrices/')\n",
    "inspect(PrecomputedDistanceMetricClustering(NB_CLUSTERS, directory/WASSER/'full_distance_matrix.pkl'), data_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energyville",
   "language": "python",
   "name": "energyville"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
