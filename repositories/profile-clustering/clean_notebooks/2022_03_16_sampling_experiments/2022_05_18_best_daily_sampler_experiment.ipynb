{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce86b18-d62d-42bd-92d7-04ab804dbf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23861863-8a72-470a-878a-a484be463c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from energyclustering.sampling.preprocessing import DataPreprocessor\n",
    "from dask.distributed import Client\n",
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fbb3aa-a03e-46b6-9a28-cc0eba4f7c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9f474-0c77-4523-bda9-28409f7bf925",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1747f318-66ca-4130-9e00-fdf30c5093fc",
   "metadata": {},
   "source": [
    "# The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098af90b-0c3f-45ca-bb67-37995fcb1cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data_df, data_df, daily_info_df, weather_df = (\n",
    "    DataPreprocessor()\n",
    "    .preprocess_info_df('baseline')\n",
    "    .preprocess_weather_df('baseline')\n",
    "    .drop_days_with_nan(True)\n",
    "    # no subsampling this time\n",
    "#     .subsample_days(week_reduction_factor = 5)\n",
    "    # for testing only!\n",
    "    .subsample_years(500)\n",
    "    .get_data()\n",
    ")\n",
    "daily_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68105e93-5608-4902-bd2e-28821001a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_info_df.loc[:, ('day_info', 'FeelsLikeC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b2577-d620-488a-a1e3-01e9a05b3185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a837238f-b5e0-4258-b16a-0f3596da88f4",
   "metadata": {},
   "source": [
    "# Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bdbb9d-69c2-4a63-a71a-74f2d13e1f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = np.random.default_rng(1)\n",
    "shuffled = data_df.index.to_numpy(copy=True)\n",
    "generator.shuffle(shuffled)\n",
    "folds = np.array_split(shuffled, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a4083a-20aa-4ecc-85de-599fc985472c",
   "metadata": {},
   "source": [
    "# Test day selection methods using consumption clustering, metadata clustering and energyville baseline\n",
    "Main idea: fix the way to select years and vary the way to select days.  \n",
    "Detail: Use consumption clustering with 50 clusters (best performing in previous experiments) to select the years .   \n",
    "Then use different strategies with different numbers of clusters to select the days and compare the different approaches.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9584780-5249-40b5-a6cc-291cd3939431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from energyclustering.sampling.samplers import ConsumptionDataSampler, MetadataSampler, EnergyvilleDaySelectionBaseline, RandomSamplerBaseline\n",
    "from energyclustering.sampling.day_of_year_samplers import DailySamplerFromClusterSampler, GenerateSampleDecorator\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.cluster import KMeans\n",
    "from pathlib import Path\n",
    "from energyclustering.sampling.evaluation.evaluation import SamplerEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ef55f-b80f-4550-a603-1fa938e40d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict()\n",
    "NB_OF_YEARLY_CLUSTERS = 50\n",
    "NB_SAMPLES = 500\n",
    "models['daily_sampling_random_baseline_0'] = (\n",
    "    GenerateSampleDecorator(\n",
    "        sampler = DailySamplerFromClusterSampler(\n",
    "            yearly_sampler = ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(), \n",
    "                clusterer = KMeans(NB_OF_YEARLY_CLUSTERS), \n",
    "                info_preprocessing = None\n",
    "            ), \n",
    "            daily_sampler = RandomSamplerBaseline(\n",
    "                n_samples = 100\n",
    "            )\n",
    "        ),\n",
    "        n_samples = NB_SAMPLES\n",
    "    )\n",
    ")\n",
    "\n",
    "models['daily_sampling_EV_baseline_0'] = (\n",
    "    GenerateSampleDecorator(\n",
    "        sampler= DailySamplerFromClusterSampler(\n",
    "            yearly_sampler = ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(), \n",
    "                clusterer = KMeans(NB_OF_YEARLY_CLUSTERS), \n",
    "                info_preprocessing = None\n",
    "            ), \n",
    "            daily_sampler = EnergyvilleDaySelectionBaseline(\n",
    "                allowed_temp_diff = 2.5\n",
    "            )\n",
    "        ), \n",
    "        n_samples = NB_SAMPLES,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "for nb_clusters in [10, 20, 30, 50]: \n",
    "    models[f'daily_sampling_consumption_{nb_clusters}'] = (\n",
    "        GenerateSampleDecorator(\n",
    "            sampler = DailySamplerFromClusterSampler(\n",
    "                yearly_sampler = ConsumptionDataSampler(\n",
    "                    classifier = RandomForestClassifier(), \n",
    "                    clusterer = KMeans(NB_OF_YEARLY_CLUSTERS), \n",
    "                    info_preprocessing = None\n",
    "                ), \n",
    "                daily_sampler = ConsumptionDataSampler(\n",
    "                    classifier = RandomForestClassifier(), \n",
    "                    clusterer = KMeans(nb_clusters), \n",
    "                    info_preprocessing = None\n",
    "                )\n",
    "            ), \n",
    "            n_samples = NB_SAMPLES,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    models[f'daily_sampling_metadata_{nb_clusters}'] = (\n",
    "        GenerateSampleDecorator(\n",
    "            sampler = DailySamplerFromClusterSampler(\n",
    "                yearly_sampler = ConsumptionDataSampler(\n",
    "                    classifier = RandomForestClassifier(), \n",
    "                    clusterer = KMeans(NB_OF_YEARLY_CLUSTERS), \n",
    "                    info_preprocessing = None\n",
    "                ), \n",
    "                daily_sampler = MetadataSampler(\n",
    "                    clusterer = KMeans(nb_clusters), \n",
    "0                )\n",
    "            ), \n",
    "            n_samples = NB_SAMPLES,\n",
    "        )\n",
    "    )\n",
    "                   \n",
    "                   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b529c0bd-a2e3-4a9c-8798-3789e1bea1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "energy_scores = []\n",
    "\n",
    "result_path = Path()/'results'/'daily_sampling2'\n",
    "result_path.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "with Client(local_directory = '/cw/dtailocal/', n_workers=30, threads_per_worker = 1) as client:\n",
    "    evaluator = SamplerEvaluator(folds, daily_data_df, daily_info_df, data_df, client, 200, crossval = True)\n",
    "    for key, model in models.items():\n",
    "        energy_score = evaluator.evaluate_and_save(model, result_path/f\"{key}.pkl\")\n",
    "        energy_scores.append(energy_score)\n",
    "    energy_scores = pd.concat(energy_scores, axis = 1, keys = models.keys())\n",
    "\n",
    "# aggregate energy scores\n",
    "plot_df = energy_scores.mean(axis = 0).to_frame('mean energy score')\n",
    "\n",
    "# parse the names\n",
    "consumption_plot_df = plot_df.assign(\n",
    "    nb_clusters = lambda x: x.index.map(lambda y: int(y.split('_')[-1])), \n",
    "    name = lambda x: x.index.map(lambda y: \"_\".join(y.split('_')[:-1]))\n",
    ").set_index(['name', 'nb_clusters'], drop = True).sort_index()\n",
    "\n",
    "\n",
    "consumption_plot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c64529-1a61-4b88-a7ef-287cf964a209",
   "metadata": {},
   "source": [
    "## Compared with metadata clustering\n",
    "Interestingly, consumption clustering seems less sensitive to a clustering that is to fine grained. \n",
    "This is probably due to the fact that the classifier cannot distinguish the different clusterings anymore and will just assign an instance to both of them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a5da7d-5ac7-487f-a806-14e0bc3fe2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = alt.Chart(consumption_plot_df.reset_index()).mark_line().encode(\n",
    "    x = 'nb_clusters:Q', \n",
    "    y = alt.Y('mean energy score:Q', scale = alt.Scale(zero = False)),\n",
    "    color = 'name:N'\n",
    "    \n",
    ")\n",
    "chart + chart.mark_circle()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energyville",
   "language": "python",
   "name": "energyville"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
