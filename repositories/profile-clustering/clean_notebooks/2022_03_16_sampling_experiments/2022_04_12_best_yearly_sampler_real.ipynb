{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce86b18-d62d-42bd-92d7-04ab804dbf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23861863-8a72-470a-878a-a484be463c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from energyclustering.sampling.preprocessing import DataPreprocessor\n",
    "from dask.distributed import Client\n",
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9f474-0c77-4523-bda9-28409f7bf925",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1747f318-66ca-4130-9e00-fdf30c5093fc",
   "metadata": {},
   "source": [
    "# The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098af90b-0c3f-45ca-bb67-37995fcb1cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data_df, data_df, daily_info_df, weather_df = (\n",
    "    DataPreprocessor()\n",
    "    .preprocess_info_df('baseline')\n",
    "    .preprocess_weather_df('baseline')\n",
    "    .drop_days_with_nan(True)\n",
    "    .subsample_days(week_reduction_factor = 5)\n",
    "    # for testing only!\n",
    "    .subsample_years(500)\n",
    "    .get_data()\n",
    ")\n",
    "daily_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68105e93-5608-4902-bd2e-28821001a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_info_df.loc[:, 'household_info']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a837238f-b5e0-4258-b16a-0f3596da88f4",
   "metadata": {},
   "source": [
    "# Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bdbb9d-69c2-4a63-a71a-74f2d13e1f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = np.random.default_rng(1)\n",
    "shuffled = data_df.index.to_numpy(copy=True)\n",
    "generator.shuffle(shuffled)\n",
    "folds = np.array_split(shuffled, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bfd8c6-89a6-4468-9a7a-56b08d23fcf9",
   "metadata": {},
   "source": [
    "# Investigate metadata sampling a bit (not a lot!)\n",
    "The conclusion is twofold: \n",
    "- (1) it seems that connection_capacity contains a whole lot less info than yearly_consumption, clustering using only yearly_consumption results in a better sampling (in terms of ES) \n",
    "- (2) it seems that a more fine grained approach is more beneficial for the sampling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1b57da-1ab2-48fe-abd4-08b4b719093e",
   "metadata": {},
   "source": [
    "### Look at the connection_power, yearly_consumption subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da00d5b4-df93-4635-805f-3bb822a41fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e71da1-5358-4756-ba96-d8674e0903ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# household info \n",
    "info = daily_info_df.loc[:, 'household_info'].drop_duplicates().droplevel('date')[['connection_power', 'yearly_consumption']]\n",
    "\n",
    "# normalize \n",
    "normalized_info = pd.DataFrame(MinMaxScaler().fit_transform(info), index = info.index, columns = info.columns)\n",
    "\n",
    "#cluster normalized\n",
    "clustering = KMeans(20).fit(normalized_info)\n",
    "normalized_info = normalized_info.assign(labels = clustering.labels_)\n",
    "\n",
    "# cluster unnormalized\n",
    "clustering = KMeans(20).fit(info)\n",
    "info = info.assign(labels = clustering.labels_)\n",
    "\n",
    "# visualize\n",
    "chart = alt.Chart(normalized_info).mark_circle().encode(\n",
    "    x = 'connection_power', \n",
    "    y= 'yearly_consumption', \n",
    "    color = 'labels:N'\n",
    ").interactive()\n",
    "\n",
    "(chart | alt.Chart(info).mark_rule(strokeWidth = 2).encode(\n",
    "    y= 'yearly_consumption', \n",
    "    color = 'labels:N'\n",
    ").interactive()).resolve_scale(color = 'independent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f61e41-88f0-4b98-b621-c11ef01ce10a",
   "metadata": {},
   "source": [
    "\n",
    "## Test different preprocessing of the info data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb50ff9b-eb45-4dd1-a152-751b642b3bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from energyclustering.sampling.samplers import MetadataSampler, RandomSamplerBaseline\n",
    "from energyclustering.sampling.day_of_year_samplers import SimilarDayFromYearSampler\n",
    "from sklearn.cluster import KMeans\n",
    "from energyclustering.sampling.evaluation import SamplerEvaluator\n",
    "from pathlib import Path\n",
    "NB_CLUSTERS = 10\n",
    "NB_DAYS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e70664-2aac-4f76-b5c6-0c08e3fb62ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoColumnsNormalized:\n",
    "    def __init__(self): \n",
    "        self.scaler = MinMaxScaler()\n",
    "    \n",
    "    def fit(self, info_df):\n",
    "        info = info_df.loc[:, ['connection_power', 'yearly_consumption']]\n",
    "        scaler = self.scaler.fit(info)\n",
    "    \n",
    "    def transform(self, info_df): \n",
    "        info_df = info_df[['connection_power', 'yearly_consumption']]\n",
    "        return pd.DataFrame(self.scaler.transform(info_df), index = info_df.index, columns = info_df.columns)\n",
    "    \n",
    "    def fit_transform(self, info_df): \n",
    "        self.fit(info_df)\n",
    "        return self.transform(info_df)\n",
    "    \n",
    "class TwoColumns:\n",
    "    def __init__(self): \n",
    "        self.scaler = MinMaxScaler()\n",
    "    \n",
    "    def fit(self, info_df):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, info_df): \n",
    "        info_df = info_df[['connection_power', 'yearly_consumption']]\n",
    "        return info_df\n",
    "    \n",
    "    def fit_transform(self, info_df): \n",
    "        self.fit(info_df)\n",
    "        return self.transform(info_df)\n",
    "    \n",
    "class OneColumn:\n",
    "    def __init__(self): \n",
    "        pass\n",
    "    \n",
    "    def fit(self, info_df):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, info_df): \n",
    "        info_df = info_df[['yearly_consumption']]\n",
    "        return info_df\n",
    "    \n",
    "    def fit_transform(self, info_df): \n",
    "        self.fit(info_df)\n",
    "        return self.transform(info_df)\n",
    "    \n",
    "class AllColumnsNormalized:\n",
    "    def __init__(self): \n",
    "        self.scaler = MinMaxScaler()\n",
    "    \n",
    "    def fit(self, info_df):\n",
    "        scaler = self.scaler.fit(info_df)\n",
    "    \n",
    "    def transform(self, info_df): \n",
    "        return pd.DataFrame(self.scaler.transform(info_df), index = info_df.index, columns = info_df.columns)\n",
    "    \n",
    "    def fit_transform(self, info_df): \n",
    "        self.fit(info_df)\n",
    "        return self.transform(info_df)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7962a54d-4060-4895-a919-e3e568bdcff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict(\n",
    "    baseline = \n",
    "        SimilarDayFromYearSampler(\n",
    "            MetadataSampler(\n",
    "                clusterer = KMeans(NB_CLUSTERS),\n",
    "                info_preprocessing = None\n",
    "            ), NB_DAYS, weather_df), \n",
    "    random = \n",
    "        SimilarDayFromYearSampler(\n",
    "            RandomSamplerBaseline(n_samples = 30),\n",
    "            NB_DAYS, weather_df\n",
    "        ),\n",
    "    all_columns = \n",
    "        SimilarDayFromYearSampler(\n",
    "            MetadataSampler(\n",
    "                clusterer = KMeans(NB_CLUSTERS),\n",
    "                info_preprocessing = AllColumnsNormalized()\n",
    "            ), NB_DAYS, weather_df), \n",
    "    two_columns = \n",
    "        SimilarDayFromYearSampler(\n",
    "            MetadataSampler(\n",
    "                clusterer = KMeans(NB_CLUSTERS),\n",
    "                info_preprocessing = TwoColumnsNormalized()\n",
    "            ), NB_DAYS, weather_df),\n",
    "    two_columns_unnormalized = \n",
    "        SimilarDayFromYearSampler(\n",
    "            MetadataSampler(\n",
    "                clusterer = KMeans(NB_CLUSTERS),\n",
    "                info_preprocessing = TwoColumns()\n",
    "            ), NB_DAYS, weather_df),\n",
    "    one_column = \n",
    "        SimilarDayFromYearSampler(\n",
    "            MetadataSampler(\n",
    "                clusterer = KMeans(NB_CLUSTERS),\n",
    "                info_preprocessing = OneColumn()\n",
    "            ), NB_DAYS, weather_df),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492399c0-364d-440e-9596-15d717f9a65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "energy_scores = []\n",
    "\n",
    "result_path = Path()/'results'/'temp'\n",
    "result_path.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "with Client(local_directory = '/cw/dtailocal/', n_workers=40, threads_per_worker = 1) as client:\n",
    "    evaluator = SamplerEvaluator(folds, daily_data_df, daily_info_df, data_df, client, 200, crossval = True)\n",
    "    for key, model in models.items():\n",
    "        energy_score = evaluator.evaluate_and_save(model, result_path/f\"{key}.pkl\")\n",
    "        energy_scores.append(energy_score)\n",
    "energy_scores = pd.concat(energy_scores, axis = 1, keys = models.keys())\n",
    "energy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d877889-9636-41b2-b006-16004b4a8a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = energy_scores.mean(axis = 0).to_frame('mean energy score')\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44081dff-3038-40ee-90e5-e258733d919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_df = plot_df.loc[['random']]\n",
    "random_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3e70cb-f621-4355-9e9f-94d3e2efb958",
   "metadata": {},
   "source": [
    "Test different amount of clusters¶## Test different amount of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c69b81-cd04-4c4c-a7dc-b21bbb282e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict()\n",
    "for nb_clusters in [1, 2, 3, 5, 10, 15,20, 30, 50, 75, 100, 150, 200]: \n",
    "    models[f'one_column_{nb_clusters}'] = SimilarDayFromYearSampler(\n",
    "            MetadataSampler(\n",
    "                clusterer = KMeans(nb_clusters),\n",
    "                info_preprocessing = OneColumn()\n",
    "            ), NB_DAYS, weather_df)\n",
    "    models[f'two_columns_{nb_clusters}'] = SimilarDayFromYearSampler(\n",
    "            MetadataSampler(\n",
    "                clusterer = KMeans(nb_clusters),\n",
    "                info_preprocessing = TwoColumnsNormalized()\n",
    "            ), NB_DAYS, weather_df)\n",
    "    models[f'tall_columns_{nb_clusters}'] = SimilarDayFromYearSampler(\n",
    "            MetadataSampler(\n",
    "                clusterer = KMeans(nb_clusters),\n",
    "                info_preprocessing = AllColumnsNormalized()\n",
    "            ), NB_DAYS, weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a06090-5999-4b12-a989-fa70d8f57c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "energy_scores = []\n",
    "\n",
    "result_path = Path()/'results'/'temp_full'\n",
    "result_path.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "with Client(local_directory = '/cw/dtailocal/', n_workers=40, threads_per_worker = 1) as client:\n",
    "    evaluator = SamplerEvaluator(folds, daily_data_df, daily_info_df, data_df, client, 200, crossval = True)\n",
    "    for key, model in models.items():\n",
    "        energy_score = evaluator.evaluate_and_save(model, result_path/f\"{key}.pkl\")\n",
    "        energy_scores.append(energy_score)\n",
    "energy_scores = pd.concat(energy_scores, axis = 1, keys = models.keys())\n",
    "\n",
    "# aggregate energy scores\n",
    "plot_df = pd.concat([energy_scores.mean(axis = 0).to_frame('mean energy score'), energy_scores.std(axis = 0).to_frame('std')], axis = 1)\n",
    "\n",
    "# parse the names\n",
    "metadata_plot_df = plot_df.assign(\n",
    "    nb_clusters = lambda x: x.index.map(lambda y: int(y.split('_')[-1])), \n",
    "    name = lambda x: x.index.map(lambda y: \"_\".join(y.split('_')[:-1])), \n",
    "    min_area = lambda x: x['mean energy score'] - x['std'], \n",
    "    max_area = lambda x: x['mean energy score'] + x['std'],\n",
    ").set_index(['name', 'nb_clusters'], drop = True).sort_index()\n",
    "\n",
    "\n",
    "metadata_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db895bbd-c947-41e5-9f00-8c659f68865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_chart(chart, fontsize = 20): \n",
    "    return chart.configure_axis(\n",
    "        grid = False, \n",
    "    labelFontSize = fontsize,\n",
    "    titleFontSize = fontsize, \n",
    "        offset = 5, \n",
    ").configure_title(\n",
    "    fontSize = fontsize\n",
    "    ).configure_legend(\n",
    "titleFontSize=fontsize,\n",
    "labelFontSize=fontsize\n",
    ").configure_view(\n",
    "    strokeWidth=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa784d-443e-48a6-a016-581d8de32f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_plot_df = metadata_plot_df.rename({'one_column':'consumption', 'two_columns':'consumption+power', 'tall_columns': 'all_features'})\n",
    "chart = alt.Chart(metadata_plot_df.reset_index()).mark_line().encode(\n",
    "    x = alt.X('nb_clusters:Q', title = '#clusters'),\n",
    "    y = alt.Y('mean energy score:Q', scale = alt.Scale(zero = False), title = 'ES'),\n",
    "    color = alt.Color('name', title = 'Used features')\n",
    ")\n",
    "random_chart = alt.Chart(random_df.reset_index()).mark_rule(color = 'gray', strokeWidth = 3).encode(\n",
    "    y = 'mean energy score:Q'\n",
    ")\n",
    "\n",
    "c = alt.layer(chart, chart.mark_circle(), random_chart).properties().configure_axis(\n",
    "    grid=False\n",
    ")\n",
    "big_chart(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad51cf-97e3-441c-ac3a-9bd532b9b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart.encode(y = alt.Y('std:Q', scale = alt.Scale(zero = False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a4083a-20aa-4ecc-85de-599fc985472c",
   "metadata": {},
   "source": [
    "# Investigate consumption clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9584780-5249-40b5-a6cc-291cd3939431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from energyclustering.sampling.samplers import ConsumptionDataSampler\n",
    "from sklearn.ensemble import RandomForestClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2cd3ac-0a33-40f0-90b6-6ce40e5f4c49",
   "metadata": {},
   "source": [
    "## Check different clusterings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee87a64d-654d-46e5-95cd-a3f6d7d7672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_extra.cluster import KMedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8a2313-e7c0-4817-aa30-b3e8c8572fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from energyclustering.clustering.similarity.wasserstein import wasserstein_distance_between_years\n",
    "from energyclustering.clustering.clusterers import MyKMedoids, PrecomputedClustering, PrecomputedDistanceMetricClustering\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from numba import jit, float64\n",
    "from pyclustering.utils.metric import type_metric, distance_metric;\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "from pyclustering.cluster.kmeans import kmeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71006b13-1aa9-46eb-9d48-a5335ebfd660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from energyclustering.webapp.resultparser import COBRASResult\n",
    "WASSER = 'full_distance_matrix_wasserstein'\n",
    "directory = Path('/cw/dtaiproj/ml/2020-FLAIR-VITO/profile-clustering/distance_matrices/')\n",
    "clustering_series, _ = COBRASResult('result_20211124_koen', directory/WASSER).get_clustering_df()\n",
    "clustering_series = clustering_series.pipe(lambda x: x.set_axis(x.index.map(str), axis = 0)).label\n",
    "clustering_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fc76e0-c21c-4390-8309-0c42c297baac",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_series.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc327e07-9308-4183-807c-f98b22c3d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(float64(float64[:], float64[:]), nogil = True, nopython = True)\n",
    "def dist(a1, a2): \n",
    "    return np.nanmean((a1-a2)**2)\n",
    "custom_metric = distance_metric(type_metric.USER_DEFINED, func = dist)\n",
    "\n",
    "class CustomKMeans: \n",
    "    def __init__(self, nb_clusters, random_state = None): \n",
    "        self.nb_clusters = nb_clusters\n",
    "    \n",
    "    def fit(self, data): \n",
    "        # initialize initial centers using K-Means++ method\n",
    "        initial_centers = kmeans_plusplus_initializer(data, self.nb_clusters).initialize()\n",
    "        # create instance of K-Means algorithm with prepared centers\n",
    "        kmeans_instance = kmeans(data, initial_centers, metric = custom_metric)\n",
    "        # run cluster analysis and obtain results\n",
    "        kmeans_instance.process()\n",
    "        labels = np.zeros(data.shape[0])\n",
    "        for cluster_idx, instance_indices in enumerate(kmeans_instance.get_clusters()): \n",
    "            labels[instance_indices] = cluster_idx\n",
    "        self.labels_ = labels.astype('int')\n",
    "        return self\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabc853e-15f9-421e-a960-c82eb2ee0988",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CLUSTERS = 40 \n",
    "models = dict(\n",
    "    expert = SimilarDayFromYearSampler(\n",
    "            ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(), \n",
    "                clusterer = PrecomputedClustering(clustering_series),\n",
    "                info_preprocessing = None\n",
    "            ), NB_DAYS, weather_df\n",
    "    ),\n",
    "    euclidean = SimilarDayFromYearSampler(\n",
    "            ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(),\n",
    "                clusterer = KMeans(NB_CLUSTERS),\n",
    "                info_preprocessing = None\n",
    "            ), NB_DAYS, weather_df\n",
    "    ),\n",
    "    wasserstein_precomputed = SimilarDayFromYearSampler(\n",
    "            ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(),\n",
    "                clusterer = PrecomputedDistanceMetricClustering(NB_CLUSTERS, directory/WASSER/'full_distance_matrix.pkl'),\n",
    "                info_preprocessing = None\n",
    "            ), NB_DAYS, weather_df\n",
    "    ),\n",
    "    euclidean_two_columns = SimilarDayFromYearSampler(\n",
    "            ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(),\n",
    "                clusterer = KMeans(NB_CLUSTERS),\n",
    "                info_preprocessing = TwoColumns()\n",
    "            ), NB_DAYS, weather_df\n",
    "    ),\n",
    "    \n",
    "    euclidean_one_column = SimilarDayFromYearSampler(\n",
    "            ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(),\n",
    "                clusterer = KMeans(NB_CLUSTERS),\n",
    "                info_preprocessing = OneColumn()\n",
    "            ), NB_DAYS, weather_df\n",
    "    ),\n",
    "    \n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113253dd-6331-4a52-aee2-24beba85b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "energy_scores = []\n",
    "\n",
    "result_path = Path()/'results'/'temp_full'\n",
    "result_path.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "with Client(local_directory = '/cw/dtailocal/', n_workers=40, threads_per_worker = 1) as client:\n",
    "    evaluator = SamplerEvaluator(folds, daily_data_df, daily_info_df, data_df, client, 200, crossval = True)\n",
    "    for key, model in models.items():\n",
    "        energy_score = evaluator.evaluate_and_save(model, result_path/f\"{key}.pkl\")\n",
    "        energy_scores.append(energy_score)\n",
    "energy_scores = pd.concat(energy_scores, axis = 1, keys = models.keys())\n",
    "\n",
    "# aggregate energy scores\n",
    "plot1_df = energy_scores.mean(axis = 0).to_frame('mean energy score')\n",
    "plot1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c77bc3-f1a4-49e2-a697-21f10715dc04",
   "metadata": {},
   "source": [
    "## Check different numbers of clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2a328b-4f6c-4eff-a371-9d0bf29f976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ef55f-b80f-4550-a603-1fa938e40d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict()\n",
    "for nb_clusters in [1, 2, 3, 5, 10, 15,20, 30, 50, 75, 100, 150, 200]:\n",
    "    models[f'euclidean_{nb_clusters}'] =  SimilarDayFromYearSampler(\n",
    "            ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(),\n",
    "                clusterer = KMeans(nb_clusters),\n",
    "                info_preprocessing = None\n",
    "            ), NB_DAYS, weather_df)\n",
    "    \n",
    "#     models[f'euclidean_calibrated_{nb_clusters}'] =  SimilarDayFromYearSampler(\n",
    "#             ConsumptionDataSampler(\n",
    "#                 classifier = CalibratedClassifierCV(RandomForestClassifier()),\n",
    "#                 clusterer = KMeans(nb_clusters),\n",
    "#                 info_preprocessing = None\n",
    "#             ), NB_DAYS, weather_df)\n",
    "    \n",
    "    \n",
    "    models[f'wasserstein_pre_{nb_clusters}'] = SimilarDayFromYearSampler(\n",
    "            ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(),\n",
    "                clusterer =  PrecomputedDistanceMetricClustering(nb_clusters, directory/WASSER/'full_distance_matrix.pkl'),\n",
    "                info_preprocessing = None\n",
    "            ), NB_DAYS, weather_df)\n",
    "    models[f'euclidean_missing_{nb_clusters}'] = SimilarDayFromYearSampler(\n",
    "            ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(),\n",
    "                clusterer = CustomKMeans(NB_CLUSTERS),\n",
    "                info_preprocessing = None,\n",
    "            ), NB_DAYS, weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c287c09-2e0b-42a9-8660-2c03542ba5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "energy_scores = []\n",
    "\n",
    "result_path = Path()/'results'/'temp'\n",
    "result_path.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "with Client(local_directory = '/cw/dtailocal/', n_workers=40, threads_per_worker = 1) as client:\n",
    "    evaluator = SamplerEvaluator(folds, daily_data_df, daily_info_df, data_df, client, 200, crossval = True)\n",
    "    for key, model in models.items():\n",
    "        energy_score = evaluator.evaluate_and_save(model, result_path/f\"{key}.pkl\")\n",
    "        energy_scores.append(energy_score)\n",
    "energy_scores = pd.concat(energy_scores, axis = 1, keys = models.keys())\n",
    "\n",
    "# aggregate energy scores\n",
    "plot_df = energy_scores.mean(axis = 0).to_frame('mean energy score')\n",
    "\n",
    "# parse the names\n",
    "consumption_plot_df = plot_df.assign(\n",
    "    nb_clusters = lambda x: x.index.map(lambda y: int(y.split('_')[-1])), \n",
    "    name = lambda x: x.index.map(lambda y: \"_\".join(y.split('_')[:-1]))\n",
    ").set_index(['name', 'nb_clusters'], drop = True).sort_index()\n",
    "\n",
    "\n",
    "consumption_plot_df.loc[('expert_COBRAS', 13), 'mean energy score'] = plot1_df.loc['expert', 'mean energy score']\n",
    "consumption_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29069c37-4175-4e33-9005-b76eb12d33bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = consumption_plot_df#.drop(index = ['euclidean_calibrated'])\n",
    "chart = alt.Chart(plot_df.reset_index()).mark_line(strokeWidth = 3).encode(\n",
    "    x = alt.X('nb_clusters:Q', title = '#clusters'),\n",
    "    y = alt.Y('mean energy score:Q', scale = alt.Scale(zero = False), title = 'ES (lower is better)'),\n",
    "    color = 'name'\n",
    ")\n",
    "\n",
    "chart = alt.layer(chart, chart.mark_circle(size = 50))\n",
    "c = random_chart + chart\n",
    "big_chart(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c64529-1a61-4b88-a7ef-287cf964a209",
   "metadata": {},
   "source": [
    "## Compared with metadata clustering\n",
    "Interestingly, consumption clustering seems less sensitive to a clustering that is to fine grained. \n",
    "This is probably due to the fact that the classifier cannot distinguish the different clusterings anymore and will just assign an instance to both of them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854f7c1-3253-4f06-8b87-5e49c529925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plot_df = (\n",
    "    pd.concat([plot_df,metadata_plot_df])\n",
    "    .sort_index()\n",
    "    .drop(index = [ 'all_features', 'consumption', 'euclidean', 'expert_COBRAS'])\n",
    "#     .loc[(slice(None), slice(0,101)),:]\n",
    ")\n",
    "all_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444beed2-1d7a-43db-bb28-be50c741806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = chart.properties(data= all_plot_df.reset_index()).encode(color = alt.Color(legend = None))\n",
    "big_chart(random_chart + chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0fd774-4130-4dac-95cd-5f10103be32a",
   "metadata": {},
   "source": [
    "## Check the decision tree and random forest behind this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d64f76-2dc5-4d61-ae81-218ea7c34734",
   "metadata": {},
   "source": [
    "### using a random forest\n",
    "We can see that connection power is being used a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda0f54-898d-47b6-a103-cff68bd6ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict(\n",
    "    euclidean = SimilarDayFromYearSampler(\n",
    "                ConsumptionDataSampler(\n",
    "                    classifier = RandomForestClassifier(),\n",
    "                    clusterer = KMeans(50),\n",
    "                    info_preprocessing = None\n",
    "                ), NB_DAYS, weather_df), \n",
    "    wasserstein = SimilarDayFromYearSampler(\n",
    "            ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(),\n",
    "                clusterer =  PrecomputedDistanceMetricClustering(50, directory/WASSER/'full_distance_matrix.pkl'),\n",
    "                info_preprocessing = None\n",
    "            ), NB_DAYS, weather_df)\n",
    ")\n",
    "\n",
    "energy_scores = []\n",
    "with Client(local_directory = '/cw/dtailocal/', n_workers=40, threads_per_worker = 1) as client:\n",
    "    evaluator = SamplerEvaluator(folds, daily_data_df, daily_info_df, data_df, client, 200, crossval = False)\n",
    "    for key, model in models.items(): \n",
    "        energy_score = evaluator.evaluate(model)\n",
    "        energy_scores.append(energy_score)\n",
    "        \n",
    "energy_scores = pd.concat(energy_scores, axis = 1, keys = models.keys())\n",
    "\n",
    "# aggregate energy scores\n",
    "plot_df = energy_scores.mean(axis = 0).to_frame('mean energy score')\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972711f2-f1f9-404a-8a2b-c67770fcec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = daily_info_df.loc[:, 'household_info'].drop_duplicates().droplevel('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d8c71d-5b76-416a-b984-a228025f8a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(columns = info.columns)\n",
    "\n",
    "\n",
    "for key, model in models.items(): \n",
    "    feature_importances.loc[key] = model.yearly_sampler.classifier.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac6f34-8a85-4dd4-a52f-573d64d92338",
   "metadata": {},
   "source": [
    "### Using a decision tree\n",
    "This performs less good but we can inspect the tree to see what happens. \n",
    "You can indeed clearly see that connection_capacity is sometimes used but only in certain cases! \n",
    "The most used feature is yearly consumption! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc3518-066a-4c68-8032-3e022bf18521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df714bab-08a5-4545-bd72-dee020d605af",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict(\n",
    "    euclidean = SimilarDayFromYearSampler(\n",
    "                ConsumptionDataSampler(\n",
    "                    classifier = DecisionTreeClassifier(max_depth = 10, min_samples_leaf = 10),\n",
    "                    clusterer = KMeans(50),\n",
    "                    info_preprocessing = None\n",
    "                ), NB_DAYS, weather_df), \n",
    "    wasserstein = SimilarDayFromYearSampler(\n",
    "            ConsumptionDataSampler(\n",
    "                classifier = DecisionTreeClassifier(max_depth = 10, min_samples_leaf = 10),\n",
    "                clusterer =  PrecomputedDistanceMetricClustering(50, directory/WASSER/'full_distance_matrix.pkl'),\n",
    "                info_preprocessing = None\n",
    "            ), NB_DAYS, weather_df)\n",
    ")\n",
    "\n",
    "energy_scores = []\n",
    "with Client(local_directory = '/cw/dtailocal/', n_workers=40, threads_per_worker = 1) as client:\n",
    "    evaluator = SamplerEvaluator(folds, daily_data_df, daily_info_df, data_df, client, 200, crossval = False)\n",
    "    for key, model in models.items(): \n",
    "        energy_score = evaluator.evaluate(model)\n",
    "        energy_scores.append(energy_score)\n",
    "        \n",
    "energy_scores = pd.concat(energy_scores, axis = 1, keys = models.keys())\n",
    "\n",
    "# aggregate energy scores\n",
    "plot_df = energy_scores.mean(axis = 0).to_frame('mean energy score')\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f058e-599a-447c-898f-eeb631f9f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(columns = info.columns)\n",
    "\n",
    "\n",
    "for key, model in models.items(): \n",
    "    feature_importances.loc[key] = model.yearly_sampler.classifier.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b3a8e4-5fc0-48a2-9f34-1380edb81bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700cc52e-f117-433c-b666-3e912575c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (100, 15), dpi = 300)\n",
    "annotations = plot_tree(models['wasserstein'].yearly_sampler.classifier, feature_names = feature_importances.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eb8c3b-e915-4e3c-a08b-437468983dff",
   "metadata": {},
   "source": [
    "## Just as a sanity check show that doing deterministic assignments is really not good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f034ec54-1bf0-4d78-a7f3-29baee236bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict(\n",
    "    deterministic = SimilarDayFromYearSampler(\n",
    "            ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(),\n",
    "                clusterer =  PrecomputedDistanceMetricClustering(50, directory/WASSER/'full_distance_matrix.pkl'),\n",
    "                info_preprocessing = None, \n",
    "                deterministic = True,\n",
    "            ), NB_DAYS, weather_df),\n",
    "    probabilistic = SimilarDayFromYearSampler(\n",
    "            ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(),\n",
    "                clusterer =  PrecomputedDistanceMetricClustering(50, directory/WASSER/'full_distance_matrix.pkl'),\n",
    "                info_preprocessing = None\n",
    "            ), NB_DAYS, weather_df),\n",
    ")\n",
    "\n",
    "energy_scores = []\n",
    "result_path = Path()/'results'/'temp_full'\n",
    "result_path.mkdir(parents = True, exist_ok = True)\n",
    "with Client(local_directory = '/cw/dtailocal/', n_workers=40, threads_per_worker = 1) as client:\n",
    "    evaluator = SamplerEvaluator(folds, daily_data_df, daily_info_df, data_df, client, 200, crossval = True)\n",
    "    for key, model in models.items(): \n",
    "        energy_score = evaluator.evaluate_and_save(model, result_path/f'{key}.pkl')\n",
    "        energy_scores.append(energy_score)\n",
    "        \n",
    "energy_scores = pd.concat(energy_scores, axis = 1, keys = models.keys())\n",
    "\n",
    "# aggregate energy scores\n",
    "plot_df = energy_scores.mean(axis = 0).to_frame('mean energy score')\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a17f8b-6b78-4ec8-ba70-ac8b7f62cdde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energyville",
   "language": "python",
   "name": "energyville"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
