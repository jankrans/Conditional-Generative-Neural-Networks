{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2688f666-7b70-4567-bc2b-8e604e7408c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c527737a-3d80-4438-99c2-d695b185e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "# alt.renderers.enable('png')\n",
    "from pathlib import Path\n",
    "\n",
    "# loading the data \n",
    "from energyclustering.sampling.preprocessing import DataPreprocessor\n",
    "\n",
    "# preprocessing the yearly info \n",
    "from energyclustering.sampling.preprocessing.info import YearlyInfoPreprocessor\n",
    "\n",
    "# executing the results in parallell \n",
    "from dask.distributed import Client\n",
    "\n",
    "# sampling models \n",
    "from energyclustering.sampling.day_of_year_samplers import RandomBaselineSampler # random day selection baseline\n",
    "from energyclustering.sampling.day_of_year_samplers import DailySamplerFromClusterSampler # to combine daily and yearly sampler\n",
    "from energyclustering.sampling.day_of_year_samplers import GenerateSampleDecorator\n",
    "from energyclustering.sampling.samplers import EnergyvilleDaySelectionBaseline\n",
    "from energyclustering.sampling.samplers import MetadataSampler\n",
    "from energyclustering.sampling.samplers import ConsumptionDataSampler\n",
    "\n",
    "\n",
    "# elbow method to use for clustering \n",
    "from energyclustering.clustering.elbow import ElbowMethod\n",
    "from energyclustering.clustering.preclustering import PreClusteringClusterer # two stage clustering procedure\n",
    "\n",
    "# clustering algorithms \n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from kmedoids import KMedoids\n",
    "from energyclustering.clustering.kmedoids import CustomKMedoids\n",
    "\n",
    "# cluster metrics \n",
    "import energyclustering.clustering.metrics as dist_metrics\n",
    "\n",
    "# classifiers \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "# evaluation \n",
    "from energyclustering.sampling.evaluation import SamplerEvaluator\n",
    "from energyclustering.sampling.evaluation.energy_score import calculate_energy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f3acb-1e93-4324-a2bb-5e4522154dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d3aa23-7c6b-4963-b786-c56177b09336",
   "metadata": {},
   "source": [
    "# The private data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8957b4-c9bb-4c21-9edd-44a4fae4a8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data_df, private_data_df, daily_info_df, weather_df = (\n",
    "    DataPreprocessor()\n",
    "    .preprocess_info_df('paper')\n",
    "    .preprocess_weather_df('paper')\n",
    "    .drop_days_with_nan(True)\n",
    "    .subsample_days(week_reduction_factor = None)\n",
    "    # for testing only!\n",
    "    # .subsample_years(1000)\n",
    "    .get_data()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d42260-d5fb-450c-8290-db4222bab4b5",
   "metadata": {},
   "source": [
    "# The public data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f042aa13-65e6-4bef-9366-62e65911abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from energyclustering.data.public.data import get_data_reading_preprocessed\n",
    "data_df = get_data_reading_preprocessed()[['Consumption']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d6aa33-c911-4d4c-8b85-b828f8231826",
   "metadata": {},
   "source": [
    "# Take info from private data df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda7958-04ff-4b61-b056-7ee96c81bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_df = data_df['Consumption'].unstack('datetime')\n",
    "private_df = private_data_df.fillna(0)\n",
    "public_df = public_df.reindex(columns = private_df.columns).fillna(0)\n",
    "assert len(private_df.columns) == len(public_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf5e83f-eeee-4159-b91d-9f5f71b3b6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "model = NearestNeighbors(n_neighbors = 1)\n",
    "model.fit(private_df) \n",
    "neigh_dist, neigh_ind = model.kneighbors(public_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02eee23-d847-4bc0-8653-8ace66d1c4e4",
   "metadata": {},
   "source": [
    "## The public dataset is a subset of the private subset although the distances are quite high \n",
    "The distances are because we processed the datasets a bit to remove the weird peaks :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f82320-8cb5-469e-ae9f-cad77bccb9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(neigh_dist[:,0]).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09279646-fc1a-4efa-9d34-4af0cf8b9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 2\n",
    "def plot_serie(serie): \n",
    "    return alt.Chart(serie.to_frame('value').reset_index(), height = 200,  width = 2000).mark_line().encode(\n",
    "        x = 'index', \n",
    "        y = 'value'\n",
    "    )\n",
    "(plot_serie(public_df.iloc[IDX]).properties(title = 'public profile') & plot_serie(private_df.iloc[neigh_ind[IDX,0]]).properties(title = 'closest match in private data')).resolve_scale(y = 'shared')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a640d05-df3e-470c-ab35-3c3bafb5145f",
   "metadata": {},
   "source": [
    "# Use the private profiles and private data that are in the public dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2e3c4e-e6f8-4b98-b569-9f56f5363795",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = private_data_df.iloc[np.unique(neigh_ind[:,0])]\n",
    "daily_info_df = daily_info_df.loc[data_df.index]\n",
    "daily_data_df = daily_data_df.loc[data_df.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55cd9a6-52a9-4523-ade1-0bb842b841ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{data_df.shape=}, {daily_info_df.shape=}, {daily_data_df.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b783a5-b42a-48e8-b746-a4a382e1da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60b1bc1-2c45-4975-8f36-aadf09131f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate folds for cross validation \n",
    "generator = np.random.default_rng(1)\n",
    "shuffled = data_df.index.to_numpy(copy=True)\n",
    "generator.shuffle(shuffled)\n",
    "folds = np.array_split(shuffled, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ce7d67-998c-4a26-a45e-cc26d0c32942",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.concatenate(folds[0:4])\n",
    "test_set = folds[4]\n",
    "print(f\"{train_set.shape=}, {test_set.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01313e72-e074-4a41-9bb8-2919c22ddbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = daily_info_df.loc[:, 'household_info'].reset_index(level = 1, drop = True).drop_duplicates()\n",
    "median_consumption = temp_df.yearly_consumption.median()\n",
    "average_profile = (temp_df.loc[test_set].yearly_consumption - median_consumption).abs().pipe(lambda x: x == x.min()).pipe(lambda x: x[x]).index[0]\n",
    "average_profile = daily_info_df.loc[[average_profile]].index[31]\n",
    "average_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fec97fd-501a-4b75-b5f1-bd1341e9dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.loc[test_set].sort_values('yearly_consumption')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6781a6-0d28-4b97-b929-6d98192844c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_profile = temp_df.loc[test_set].sort_values('yearly_consumption').index[-1]\n",
    "high_profile = daily_info_df.loc[[high_profile]].index[29]\n",
    "high_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48ae151-3d5a-439a-936b-4b89bb66cb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.index.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104bfe5-ce1d-49ea-9ccb-09b91de51d3f",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f0452e-2c33-45ee-b8cd-3683a60aadfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_SAMPLES = 100\n",
    "# CLUSTER_RANGE = list(range(10, 101, 5))\n",
    "CLUSTER_RANGE = list(range(5, 41, 5))\n",
    "models = dict()\n",
    "\n",
    "# random baseline \n",
    "models['random baseline'] = RandomBaselineSampler(NB_SAMPLES)\n",
    "\n",
    "# rule based approach \n",
    "models['expert based'] = (\n",
    "    GenerateSampleDecorator(\n",
    "        sampler = DailySamplerFromClusterSampler(\n",
    "            yearly_sampler = MetadataSampler(\n",
    "                clusterer = ElbowMethod(KMeans(n_clusters = 1, n_init = 10), cluster_range = CLUSTER_RANGE), \n",
    "                info_preprocessing = YearlyInfoPreprocessor(columns_to_use = ['yearly_consumption', 'connection_power'], normalized = True),\n",
    "            ), \n",
    "            daily_sampler = EnergyvilleDaySelectionBaseline()\n",
    "        ), \n",
    "        n_samples = NB_SAMPLES,\n",
    "    )\n",
    ")\n",
    "\n",
    "# consumption clustering based approach \n",
    "models['data driven'] = (\n",
    "     GenerateSampleDecorator(\n",
    "        sampler = DailySamplerFromClusterSampler(\n",
    "            yearly_sampler = ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(),\n",
    "                clusterer = ElbowMethod(KMedoids(n_clusters = 1, method = 'fasterpam'), metric = dist_metrics.euc_distance_matrix_missing, cluster_range = CLUSTER_RANGE, nb_repeats = 10), \n",
    "#                 clusterer = ElbowMethod(KMeans(n_clusters = 1, n_init = 1), metric = None, cluster_range = CLUSTER_RANGE, nb_repeats = 1), \n",
    "#                 clusterer = KMeans(n_clusters = 5, n_init = 10), \n",
    "                fillna = False,\n",
    "#                 fillna = True,\n",
    "            ), \n",
    "            daily_sampler = ConsumptionDataSampler(\n",
    "                classifier = RandomForestClassifier(),\n",
    "                clusterer = ElbowMethod(\n",
    "                    clusterer = KMeans(n_clusters = 1),\n",
    "                    cluster_range = CLUSTER_RANGE,\n",
    "#                     show_progress = True,\n",
    "                ), \n",
    "#                 clusterer = KMeans(n_clusters = 30, n_init = 1), \n",
    "            ), \n",
    "#             show_progress= True,\n",
    "        ), \n",
    "        n_samples = NB_SAMPLES,\n",
    "    )\n",
    ")\n",
    "\n",
    "# models['data driven fixed'] = (\n",
    "#      GenerateSampleDecorator(\n",
    "#         sampler = DailySamplerFromClusterSampler(\n",
    "#             yearly_sampler = ConsumptionDataSampler(\n",
    "#                 classifier = RandomForestClassifier(),\n",
    "#                 clusterer = CustomKMedoids(n_clusters = 50, metric = dist_metrics.euc_distance_matrix_missing), \n",
    "# #                 clusterer = ElbowMethod(KMeans(n_clusters = 1, n_init = 1), metric = None, cluster_range = CLUSTER_RANGE, nb_repeats = 1), \n",
    "# #                 clusterer = KMeans(n_clusters = 5, n_init = 10), \n",
    "#                 fillna = False,\n",
    "# #                 fillna = True,\n",
    "#             ), \n",
    "#             daily_sampler = ConsumptionDataSampler(\n",
    "#                 classifier = RandomForestClassifier(),\n",
    "#                 clusterer = KMeans(n_clusters = 25)\n",
    "# #                     show_progress = True, \n",
    "# #                 clusterer = KMeans(n_clusters = 30, n_init = 1), \n",
    "#             ), \n",
    "# #             show_progress= True,\n",
    "#         ), \n",
    "#         n_samples = NB_SAMPLES,\n",
    "#     )\n",
    "# )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f3a36-393b-4fc9-bed4-f6c439676dff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask_util import get_dask_cluster\n",
    "cluster = get_dask_cluster(\n",
    "    pinac_numbers = [],\n",
    "    himec_numbers = [8, 1, 2],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fdcb2b-6398-4ff8-b503-2efde6bdcba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with Client(cluster) as client: \n",
    "    all_energy_scores = []\n",
    "    for model_name, model in models.items(): \n",
    "        evaluator = SamplerEvaluator(folds, daily_data_df, daily_info_df, data_df, client, 100, crossval = False) \n",
    "        energy_scores = evaluator.evaluate(model)\n",
    "        all_energy_scores.append(energy_scores)\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27e4079-5e66-4bdd-8cbc-efb834849093",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_energy_scores = pd.concat(all_energy_scores, axis = 1, keys = models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde7006d-da69-4e1f-aab6-754e123042e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_energy_scores = all_energy_scores.mean(axis = 1).sort_values()\n",
    "mean_energy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4db6e13-731b-4c88-b04b-bd7f05e56c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_modelled_profile = mean_energy_scores.index[int(0.25*mean_energy_scores.shape[0])]\n",
    "bad_modelled_profile = mean_energy_scores.index[int(0.75*mean_energy_scores.shape[0])]\n",
    "well_modelled_profile, bad_modelled_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d0f80b-936c-4d67-a9d1-38a2325f7392",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_info_df.loc[average_profile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378638d-15ed-490f-afb7-eb3af2ec04c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = daily_info_df.loc[[average_profile[0]]].pipe(lambda x: x[(x[('day_info', 'dayOfWeek')] == 0 ) & (x[('day_info', 'month')].isin([1,2,3]))])\n",
    "plot_df = transform(daily_data_df.loc[plot_df.index]).assign(meter = lambda x: x.meter.astype('str'))\n",
    "plot_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12805241-3f3e-4fad-bd63-5b54c236c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "variability_chart = alt.Chart(plot_df).mark_line(strokeWidth = 1, opacity = 0.5, color = 'blue').encode(\n",
    "            x = alt.X('timestamp:T',  axis=alt.Axis(format='%H:%M')),\n",
    "            y = 'value', \n",
    "            detail = 'meter'\n",
    "        )\n",
    "variability_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ab22db-e9e6-4a05-a8db-f10f9bbf2689",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform(data): \n",
    "    data.index = [str(index) for index in data.index]\n",
    "    plot_df = data.stack().to_frame('value').reset_index().set_axis(['meter', 'timestamp', 'value'], axis = 1)\n",
    "    return plot_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b217c2-65f5-4a8c-b940-b4537e5cebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_translation = {'random baseline': 'Random sampling', 'expert based': 'Expert-based', 'data driven': 'Data-driven'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a4121a-7104-4be4-a6a5-3f24da21146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_quantile(models, quantile): \n",
    "    profile = mean_energy_scores.index[int(quantile*mean_energy_scores.shape[0])]\n",
    "    return make_plot(models, profile)\n",
    "def make_plot_index(models,index): \n",
    "    profile = mean_energy_scores.index[index]\n",
    "    return make_plot(models, profile)\n",
    "\n",
    "def make_plot(models, profile): \n",
    "    charts = []\n",
    "    real_data = daily_data_df.loc[[profile]]\n",
    "    plot_df_real = transform(real_data)\n",
    "    \n",
    "    real_info = daily_info_df.loc[[profile]]\n",
    "\n",
    "    \n",
    "    # real_day = real_info[('day_info', 'dayOfWeek')].iloc[0]\n",
    "    # display(real_day)\n",
    "    # real_month = real_info[('day_info', 'month')].iloc[0]\n",
    "    # plot_df = daily_info_df.loc[[average_profile[0]]].pipe(lambda x: x[(x[('day_info', 'dayOfWeek')] == real_day ) & (x[('day_info', 'month')].isin([real_month -1 ,real_month,real_month + 1]))])\n",
    "    # plot_df = transform(daily_data_df.loc[plot_df.index]).assign(meter = lambda x: x.meter.astype('str'))\n",
    "    # variability_chart = alt.Chart(plot_df, title = 'Daylong time series of similar days').mark_line(strokeWidth = 1, opacity = 0.5, color = 'blue').encode(\n",
    "    #         x = alt.X('timestamp:T',  axis=alt.Axis(format='%H:%M')),\n",
    "    #         y = 'value', \n",
    "    #         detail = 'meter'\n",
    "    #     )\n",
    "                                                                       \n",
    "    for model_name, model in models.items(): \n",
    "        predicted_data = model.get_sampling_probabilities_daily(real_info)[0]\n",
    "        predicted_scenarios = daily_data_df.loc[predicted_data.index]\n",
    "        plot_df_pred_subset = transform(predicted_scenarios.sample(5))\n",
    "        plot_df_pred = transform(predicted_scenarios)\n",
    "        \n",
    "        probs = np.full((NB_SAMPLES,), 1/NB_SAMPLES)\n",
    "        samples = daily_data_df.loc[predicted_data.index].to_numpy()\n",
    "        truth = real_data.to_numpy()[0,:]\n",
    "        calculated_energy_score = calculate_energy_score(probs, samples, truth)\n",
    "        \n",
    "        predicted_chart = alt.Chart(plot_df_pred).mark_line(opacity = 0.3, strokeWidth = 0.5,  color = 'gray').encode(\n",
    "            x = alt.X('timestamp',  title = None,  axis=alt.Axis(format='%H:%M')),\n",
    "            y = alt.Y('value', title = 'Load (in kWh)'),\n",
    "            detail =  'meter',\n",
    "        )\n",
    "        real_chart = alt.Chart(plot_df_real).mark_line(strokeWidth = 1, color = 'blue').encode(\n",
    "            x = alt.X('timestamp',  title = None,  axis=alt.Axis(format='%H:%M')),\n",
    "            y = alt.Y('value', title = 'Load (in kWh)'),\n",
    "        )\n",
    "        subset_chart = alt.Chart(plot_df_pred_subset).mark_line().encode(\n",
    "             x = alt.X('timestamp',  title = None,  axis=alt.Axis(format='%H:%M')),\n",
    "            y = alt.Y('value', title = 'Load (in kWh)'),\n",
    "            color =  alt.Color('meter', legend = None, scale = alt.Scale(scheme = 'tableau10' )),\n",
    "        )\n",
    "        # charts.append( (predicted_chart + real_chart).properties(title = f\"{model_translation[model_name]} (ES = {calculated_energy_score:.3f})\").interactive(bind_x = False))\n",
    "        charts.append(( (predicted_chart + real_chart).properties(title = f\"{model_translation[model_name]}\") & subset_chart).resolve_scale(y='shared').resolve_axis(y = 'shared'))\n",
    "    return alt.hconcat(*charts).resolve_scale(y = 'shared', color = 'independent').resolve_axis(y = 'shared')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963e72d3-cfaf-4c30-8138-6310824ba1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chart_util import big_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b13ddf7-db9a-41e7-8e15-c4fe3719468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_chart(make_plot(models, average_profile), fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f962b7ab-14be-49fc-8199-77ec5e599beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_chart(make_plot(models, high_profile), fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fefb3c-f4e5-4d82-bb37-e78e39497edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_info_df.loc[average_profile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3307716-cf72-4804-a71c-36e57b06009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = daily_info_df.loc[[average_profile[0]]].pipe(lambda x: x[(x[('day_info', 'dayOfWeek')] == 0 ) & (x[('day_info', 'month')].isin([1,2,3]))])\n",
    "plot_df = transform(daily_data_df.loc[plot_df.index]).assign(meter = lambda x: x.meter.astype('str'))\n",
    "plot_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef19134-0c6f-4df8-8240-2767e085249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "variability_chart = alt.Chart(plot_df).mark_line(strokeWidth = 1, opacity = 0.5, color = 'blue').encode(\n",
    "            x = alt.X('timestamp:T',  axis=alt.Axis(format='%H:%M')),\n",
    "            y = 'value', \n",
    "            detail = 'meter'\n",
    "        )\n",
    "variability_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ccd2b-d115-4394-93dc-f76bbd9289d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energyville",
   "language": "python",
   "name": "energyville"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
