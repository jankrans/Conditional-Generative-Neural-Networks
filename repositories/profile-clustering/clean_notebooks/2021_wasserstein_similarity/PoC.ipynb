{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2a487d-10b1-449b-a01b-1d2604101584",
   "metadata": {},
   "source": [
    "# New idea: histogram similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15fabea-8b6d-4366-913c-173eabd8a8cf",
   "metadata": {},
   "source": [
    "The histogram similarity would simply for each time of day make a histogram of all the consumption measurements of a certain profile during that timestamp.  \n",
    "To compare two profiles all time-of-day histograms of the two profiles are compared using the wasserstein_distance (implementation in [scipy.stats.wasserstein_distance](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wasserstein_distance.html)). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cfb9d1-abd0-4db1-af28-2a9b88dfa413",
   "metadata": {},
   "source": [
    "## Wasserstein distance\n",
    "\n",
    "This distance is also known as the earth mover's distance, since it can be\n",
    "seen as the minimum amount of \"work\" required to transform $u$ into\n",
    "$v$, where \"work\" is measured as the amount of distribution weight\n",
    "that must be moved, multiplied by the distance it has to be moved.\n",
    "\n",
    "**Interestingly** You can weight the different bins of a histogram to give more weight to some bins! We can use this to put extra emphasis on high peaks if we want! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07101418-70e3-4672-a295-3f6cab301034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "wasserstein_distance([1,2,3], [4,5,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d087f615-de72-4f3b-ba5d-8155fd67aa4b",
   "metadata": {},
   "source": [
    "### Building the histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f7b7e6-ba2f-40fd-b7da-e12c5f324276",
   "metadata": {},
   "source": [
    "To build the histograms, we need to ensure that the bins are the same for each profile OR that the bins are the same for each pairs of profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc70660d-666a-44e4-8f76-cbcf69070e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from energyclustering.data.fluvius import read_data_pickle\n",
    "info_df, data_df = read_data_pickle(include_incomplete_profiles = False, process_errors = True)\n",
    "data_df = data_df.rename_axis('timestamp', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c603255-e618-4126-b6ca-528060e2da45",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = data_df.sample(5, random_state = 1234)\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9b8b6c-0bbb-44b7-a4b8-92ddf0724e4e",
   "metadata": {},
   "source": [
    "### Try overall histogram\n",
    "So this is also not good! Because the histogram boundaries are different for every timestep.  \n",
    "In this way a difference of 1kW during a timestamp with a large range will contribute less to the overall distance than a difference of 1kW for a timestamp with a lower range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2ad4b3-6fb9-4214-8960-227b98b09fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5680fa17-6f92-4da7-80e5-a4422a389b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date(series):\n",
    "    return pd.to_datetime(series, format='%H:%M:%S', exact = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c426482-365d-4df5-ad51-3f7a606ea978",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = (\n",
    "        data_df\n",
    "        .rename_axis('timestamp', axis = 1)\n",
    "        .stack().to_frame('value')\n",
    "        .assign(\n",
    "            time=lambda x: add_date(x.index.get_level_values('timestamp').time),\n",
    "            date=lambda x: x.index.get_level_values('timestamp').date.astype('str')\n",
    "        )\n",
    "        .pipe(lambda x: pd.pivot_table(x, index=['meterID','year','date'], columns=['time'], values='value', dropna= False))\n",
    "        # go to hourly consumption\n",
    "        .resample('4H', axis = 1).sum()\n",
    "    )\n",
    "\n",
    "daily_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab32a4f-e924-4eec-957a-57c0d5e73a1f",
   "metadata": {},
   "source": [
    "## Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c652c-55f3-48ce-a282-632478e582d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "from energyclustering.visualization.cluster_visualization import all_day_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3845e48-6a9e-4afd-89c3-5e69b74140b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROFILE_TO_PLOT = data_df.index[3]\n",
    "PROFILE2_TO_PLOT = data_df.index[0]\n",
    "plot_df1 = daily_df.loc[PROFILE_TO_PLOT].stack().to_frame('value').reset_index().assign(time = lambda x: x.time.dt.strftime('%H:%M'))\n",
    "plot_df2 = daily_df.loc[PROFILE2_TO_PLOT].stack().to_frame('value').reset_index().assign(time = lambda x: x.time.dt.strftime('%H:%M'))\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize = (14,6), sharey = True)\n",
    "ax = sns.violinplot(ax = axes[0], x=\"time\", y=\"value\", data=plot_df1)\n",
    "ax = sns.violinplot(ax = axes[1], x = 'time', y='value', data=plot_df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f37176f-cf31-4a97-8365-f800f477b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_day_plot(PROFILE_TO_PLOT, data_df.resample('4H', axis = 1).sum()).properties(width = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41e09d-4a35-4a02-9490-c715cfaed33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df.index.droplevel('date').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4802e1df-643b-4011-8390-2e3f40936ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_values, max_values = daily_df.min(axis = 0), daily_df.max(axis = 0)\n",
    "max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f99552-2593-4d3b-b6f6-ebc2370c7ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_BINS = 10\n",
    "histogram_dict = dict()\n",
    "for profile, profile_df in daily_df.groupby('meterID'):\n",
    "    histograms = np.zeros((24, NB_BINS))\n",
    "    for idx, column in enumerate(profile_df.columns): \n",
    "        values = profile_df[column]  \n",
    "        hist, bin_edges = np.histogram(values, bins = NB_BINS, range=(min_values[column], max_values[column]))\n",
    "        histograms[idx, :] = hist\n",
    "    histogram_dict[profile] = histograms\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154e1c0-61f9-47ac-b4bc-568845d6ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_entries = []\n",
    "for profile1, profile2 in itertools.combinations(histogram_dict.keys(), 2): \n",
    "    distances = []\n",
    "    for histogram_idx in range(histogram_dict[profile1].shape[0]):\n",
    "        distance = wasserstein_distance(histogram_dict[profile1][histogram_idx], histogram_dict[profile2][histogram_idx])\n",
    "        distances.append(distance)\n",
    "    distance_entries.append((profile1, profile2, np.sum(distances)))\n",
    "distance_df = pd.DataFrame(distance_entries, columns = ['p1', 'p2', 'distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056e9bb-c83b-4e0f-8e5b-494f60335452",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_df.sort_values('distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116b0ac4-731d-47ad-b9d9-5f89b89fb8ef",
   "metadata": {},
   "source": [
    "## Try pairwise histogram\n",
    "So of course this does not work! Because the scale should be the same for all comparisons. (e.g. if 10 bins becomes a difference from 1kW another comparison where 10 bins is equal to 10 kW) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d969dd-88ab-4882-9d20-e059c4b4bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_distance(values1, values2): \n",
    "    NB_BINS = 10\n",
    "    min_value = min(values1.min(), values2.min())\n",
    "    max_value = max(values1.max(), values2.max())\n",
    "    hist1, _ = np.histogram(values1, NB_BINS, range = (min_value, max_value))\n",
    "    hist2, _ = np.histogram(values2, NB_BINS, range = (min_value, max_value))\n",
    "    return wasserstein_distance(hist1, hist2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07e8341-d0fd-4d3b-951a-845ead51e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_entries = []\n",
    "profiles = daily_df.index.get_level_values(0).unique()\n",
    "for p1, p2 in itertools.combinations(profiles, 2): \n",
    "    p1_df = daily_df.loc[p1]\n",
    "    p2_df = daily_df.loc[p2] \n",
    "    distances = []\n",
    "    for column in p1_df: \n",
    "        distance = histogram_distance(p1_df[column], p2_df[column]) \n",
    "        distances.append(distance)\n",
    "    distance_entries.append((p1, p2, np.sum(distances)))\n",
    "distance_df = pd.DataFrame(distance_entries, columns = ['p1', 'p2', 'distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318c1945-ae68-42ca-ae27-43e2460ca7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_df.sort_values('distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ee57f3-82aa-49b3-ae27-d8ffb4eba3e1",
   "metadata": {},
   "source": [
    "# Look at results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a82ae41-5682-4c57-9ba2-0166b010e7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from energyclustering.webapp.resultparser import ResultParser, ResultComparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eacfe9-f055-4ee3-9845-9a88d897a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HIST = 'histogram_bins_20'\n",
    "hist_result = ResultParser('result_20210628_koen', HIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cfe004-6373-419a-87a2-fb1a089e21b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_result.distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee77e059-5c8f-453c-b88b-d19305cea6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energyville",
   "language": "python",
   "name": "energyville"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
