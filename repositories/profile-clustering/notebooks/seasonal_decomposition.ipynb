{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EnergyVille: seasonal decomposition try-out - v2\n",
    "- simple missing value imputation by taking the average of the previous day and the next day\n",
    "- seasonal decomposition of time series\n",
    "- correlation between the trend component and the weather\n",
    "- clustering of the seasonal component to represent daily patterns in a year (this may be useful in EnergyVille)\n",
    "- average daily consumption pattern\n",
    "\n",
    "## Imports and set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a bit hacky, so let me know if you have a better way of doing this. But to use the src, and maybe this is good practice in general, we need to run the notebook from the root folder of the repo.\n",
    "%pwd\n",
    "%cd ../\n",
    "\n",
    "# %qtconsole # open an interactive console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose, STL\n",
    "import altair as alt\n",
    "from altair.expr import datum\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "alt.data_transformers.disable_max_rows()\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path().absolute() / 'data'/ 'consumption.csv'\n",
    "\n",
    "import energy_ville.data as evd\n",
    "import data_cleaning.find_problems_in_data as fpid\n",
    "\n",
    "import sklearn_extra.cluster as clstr\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table = evd.get_master_table()\n",
    "# data_reading_full = evd.get_data_reading_full()\n",
    "df = evd.get_data_reading_preprocessed()\n",
    "\n",
    "iIDs = fpid.get_iID_info()[0]\n",
    "\n",
    "time_indices_full, time_first, time_last = fpid.get_time_info()\n",
    "\n",
    "df = df.reindex(pd.MultiIndex.from_product([df.index.levels[0], time_indices_full], names=['iID', 'datetime'])) # add missing time samples (if any) as NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing values using seasonal mean\n",
    "The seasonal mean can be calculated either from all periods or from only the previous and next periods (for which the corresponding time sample is not missing) because the STL decomposition methods *cannot* handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_seasonal_mean(ts, n, lr=1): # function taken from https://www.machinelearningplus.com/time-series/time-series-analysis-python/\n",
    "    \"\"\"\n",
    "    Compute the mean of corresponding seasonal periods\n",
    "    ts: 1D array-like of the time series\n",
    "    n: Seasonal window length of the time series\n",
    "    \"\"\"\n",
    "    out = np.copy(ts)\n",
    "    for i, val in enumerate(ts):\n",
    "        if np.isnan(val):\n",
    "            ts_seas = ts[i::-n]  # previous seasons only\n",
    "            if np.isnan(np.nanmean(ts_seas)):\n",
    "                ts_seas = np.concatenate([ts[i-1::-n], ts[i::n]])  # previous and forward\n",
    "            out[i] = np.nanmean(ts_seas) * lr\n",
    "    return out\n",
    "\n",
    "def calculate_two_period_seasonal_mean(ts, n):\n",
    "    \"\"\"\n",
    "    Fill missing values by the average of the corresponding time samples in the previous period and the next period\n",
    "    ts: 1D array-like of the time series\n",
    "    n: Seasonal window length of the time series\n",
    "    \"\"\"\n",
    "    out = np.copy(ts)\n",
    "    for i, val in enumerate(ts):\n",
    "        if np.isnan(val):\n",
    "            \n",
    "            ts_prev = ts[i::-n]  # values in the previous periods\n",
    "            ts_next = ts[i::n]  # values in the next periods\n",
    "            \n",
    "            ind_prev = np.where(~np.isnan(ts_prev))[0][0:] # latest non-NaN value in the past\n",
    "            ind_next = np.where(~np.isnan(ts_next))[0][0:] # first non-NaN value in the future\n",
    "            \n",
    "            pr = ts_prev[ind_prev[0]] if ind_prev.size != 0 else np.nan\n",
    "            nx = ts_next[ind_next[0]] if ind_next.size != 0 else np.nan\n",
    "            \n",
    "            out[i] = np.nanmean([pr,] + [nx,])\n",
    "    return out\n",
    "\n",
    "number_of_samples_per_day = round(len(time_indices_full) / (time_indices_full[-1] - time_indices_full[0]).days)\n",
    "\n",
    "df_orig = copy.deepcopy(df)\n",
    "\n",
    "# df = df.groupby(level=0).transform(lambda o: calculate_seasonal_mean(o, n=number_of_samples_per_day))\n",
    "df = df.groupby(level=0).transform(lambda o: calculate_two_period_seasonal_mean(o, n=number_of_samples_per_day))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition using STL:\n",
    "The parameter *period* should be 48 (the number of samples in a day) or 48\\*7 for weekly periodicity.\n",
    "\n",
    "When the parameter *seasonal* is increased, the seasonal component changes more slowly. I selected it as 91 just because a season lasts for 3 months and it has to be an odd number. \n",
    "\n",
    "*robust* option gives a smoother trend signal.\n",
    "\n",
    "Execution takes too long for the whole dataset, so let's calculate decomposition for a small subset of iIDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iID_inds_to_calculate = np.random.choice(len(iIDs), 3, replace=False)\n",
    "iID_inds_to_calculate = list(range(len(iIDs)))\n",
    "iIDs_to_calculate = iIDs[iID_inds_to_calculate]\n",
    "\n",
    "grouped = df.groupby(level=0)\n",
    "\n",
    "for iID, group in tqdm(grouped):\n",
    "    if iID in iIDs_to_calculate:\n",
    "        # result = seasonal_decompose(group.Consumption, period = number_of_samples_per_day)\n",
    "        result = STL(group.Consumption, period = number_of_samples_per_day, seasonal = 181, robust = True).fit()\n",
    "\n",
    "        df.loc[iID, 'Consumption_Seasonal'] = result.seasonal.values # all three are for \"Consumption\"\n",
    "        df.loc[iID, 'Consumption_Trend'] = result.trend.values\n",
    "        df.loc[iID, 'Consumption_Resid'] = result.resid.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = copy.deepcopy(df)\n",
    "plot_df.drop(['Offtake', 'Injection'], axis=1, inplace=True)\n",
    "\n",
    "plot_df = plot_df.loc[iIDs_to_calculate[91]] # select one iID among the computed ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df1 = plot_df.stack(dropna=False).reset_index()\n",
    "plot_df1.columns = ['datetime', 'score_type', 'value']\n",
    "plot_df1.head()\n",
    "alt.Chart(plot_df1).mark_line(strokeWidth=0.5).encode(\n",
    "        x = 'datetime:T', \n",
    "        y = alt.Y('value:Q', title=''),\n",
    "        row = alt.Row('score_type:N', sort = 'ascending')\n",
    ").properties(width=2000, height=100\n",
    ").resolve_scale(y='independent'\n",
    ").interactive()#.facet(row = 'score_type:N', data = plot_df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster seasonal time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_extra.cluster as clstr\n",
    "\n",
    "plot_df['date'] = pd.to_datetime(plot_df.index.date)\n",
    "\n",
    "grp = plot_df.groupby(plot_df.date).Consumption_Seasonal\n",
    "dates = []\n",
    "ts = []\n",
    "grps = []\n",
    "for key, gr in grp:\n",
    "    dates.append(key)\n",
    "    ts.append(gr.values)\n",
    "    grps.append(gr)\n",
    "\n",
    "n_clusters = 4\n",
    "kmedoids = clstr.KMedoids(n_clusters=n_clusters, random_state=73).fit(ts)\n",
    "\n",
    "plot_df['cluster'] = ''\n",
    "for i, date in enumerate(dates):\n",
    "    plot_df.loc[plot_df.date==date, 'cluster'] = kmedoids.labels_[i]\n",
    "\n",
    "plot_df['cluster_medoid'] = False\n",
    "for i in range(n_clusters):\n",
    "    plot_df.loc[plot_df.date==dates[kmedoids.medoid_indices_[i]], 'cluster_medoid'] = True\n",
    "\n",
    "plot_df = plot_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(plot_df).mark_line().encode(\n",
    "    x = alt.X('datetime:T', title='date&time', scale=alt.Scale(domain=('2016-01-01 00:00:00', '2017-01-01 00:00:00'))),\n",
    "    y = alt.Y('Consumption_Seasonal:Q', title='seasonal component'),\n",
    "    color=alt.Color('cluster:O', legend=alt.Legend(title='cluster'), scale=alt.Scale(scheme='dark2')), \n",
    "    size = alt.Size('cluster_medoid:O', legend=alt.Legend(title='cluster medoids'))\n",
    ").properties(width=6000, height=200).interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_df['timeoftheday'] = plot_df.time.dt.time\n",
    "\n",
    "alt.Chart(plot_df[plot_df.cluster_medoid]).mark_line().encode(\n",
    "   x = alt.X('hoursminutes(datetime):O', title='time of the day'),\n",
    "    y = alt.Y('Consumption_Seasonal:Q', title='seasonal component'),\n",
    "    color=alt.Color('cluster:O', legend=alt.Legend(title='cluster medoids'), scale=alt.Scale(scheme='dark2'))\n",
    ").properties(width=500, height=200).interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
