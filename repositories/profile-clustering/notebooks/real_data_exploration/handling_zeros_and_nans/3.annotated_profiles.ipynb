{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate annotated profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import datetime\n",
    "import random\n",
    "idx = pd.IndexSlice\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this reloads code from external modules automatically if it is changed (without having to restart the kernel)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interval_information import get_interval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_PATH = Path('/cw/dtaiproj/ml/2020-FLAIR-VITO/profile-clustering/preprocessed/combined')\n",
    "RESULT_PATH = Path('/cw/dtaiproj/ml/2020-FLAIR-VITO/profile-clustering/error_detection')\n",
    "RESULT_PATH.mkdir(mode = 0o770, parents = True, exist_ok=True)\n",
    "result_path = RESULT_PATH / 'cumulative_value_detection.csv' \n",
    "zero_path = RESULT_PATH / 'zero_interval_is_error.csv'\n",
    "interval_path = RESULT_PATH /'intervals_with_info.csv'\n",
    "info_path = PRE_PATH/'info.csv'\n",
    "data_path = PRE_PATH/'data.csv'\n",
    "assert info_path.exists() and data_path.exists() and zero_path.exists(), 'These paths should exist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read info and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = pd.read_csv(info_path, index_col = [0,1])\n",
    "data_df = pd.read_csv(data_path, index_col = [0,1])\n",
    "data_df.columns = pd.to_datetime(data_df.columns)\n",
    "data_df.columns.name = 'timestamp'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE = 'EandisVREG'\n",
    "YEAR = 2016\n",
    "# get the right subset based on the info df\n",
    "info16_df = info_df.loc[idx[:, 2016],:]\n",
    "info16_df = info16_df[info16_df.data_source == 'EandisVREG']\n",
    "\n",
    "# read the corresponding data profiles \n",
    "data16_df = data_df.loc[info16_df.index, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read zero errors and cumulative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_detections = pd.read_csv(zero_path).set_index(['meterID', 'year', 'start', 'end'], drop = True)\n",
    "cumulative_value_detections = pd.read_csv(result_path).set_index(['meterID', 'year', 'start', 'end'], drop = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only investigate timeseries with data problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb of zeros for each profile\n",
    "nb_of_zeros = (data16_df == 0).sum(axis = 1)\n",
    "nb_of_nan = data16_df.isna().any(axis =1 )\n",
    "data16_df= data16_df.loc[(nb_of_zeros>0) | nb_of_nan]\n",
    "# data16_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the intervals\n",
    "So in the rest of this code we simply construct the intervals as a dataset and add different attributes/features and investigate whether they could be useful or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "interval_df = get_interval_df(data16_df, info16_df, keep_zero = True, keep_nan = True)\n",
    "# interval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = interval_df.join(zero_detections).join(cumulative_value_detections)\n",
    "intervals.loc[interval_df.interval_value.isna(), 'is_error'] = True \n",
    "intervals = intervals.rename(columns = {'followed_by_cumulative_value':'is_cumulative_value'})\n",
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals.to_csv(interval_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsample these at random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(331345)\n",
    "# meterIDs = np.random.choice(intervals.index.get_level_values(0).unique(), 10, replace = False)\n",
    "# data16_df = data16_df.loc[meterIDs].sort_index()\n",
    "# intervals = intervals.loc[meterIDs].sort_index()\n",
    "# del interval_df\n",
    "# del info16_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_profile(meterID, year):\n",
    "    # plots the profile, using the period data in data \n",
    "    # the color can be determined using the period_type_column\n",
    "    \n",
    "    \n",
    "    profile_df = data16_df.loc[(meterID, year),:].to_frame('value').reset_index()\n",
    "    profile_intervals =intervals.loc[(meterID,year), :].reset_index(drop = True).fillna({'is_cumulative_value':\"don't know\"})\n",
    "    profile_intervals.loc[profile_intervals.interval_value.isna(), 'interval_type'] = 'error'\n",
    "    profile_intervals.loc[(profile_intervals.interval_value == 0) & (profile_intervals.is_error), 'interval_type'] = 'error'\n",
    "    profile_intervals.loc[(profile_intervals.interval_value == 0) & (profile_intervals.is_error.isna()), 'interval_type'] = \"don't know\"\n",
    "    profile_intervals.loc[(profile_intervals.interval_value == 0) & (profile_intervals.is_error == False), 'interval_type'] = 'normal'\n",
    "        \n",
    "\n",
    "    line = alt.Chart(profile_df).mark_line().encode(\n",
    "        x = alt.X('timestamp:T', title = 'timestamp'), \n",
    "        y = alt.Y('value:Q', title = 'consumption (in kWh)')\n",
    "    )\n",
    "    interval_type_color = alt.Color('interval_type:N', \n",
    "                                            scale = alt.Scale(\n",
    "                                                domain = ['normal', \"don't know\", \"error\"], \n",
    "                                            ))\n",
    "    period_shading = alt.Chart(profile_intervals).mark_rect(opacity = 0.6).encode(\n",
    "        x = 'start_time:T',\n",
    "        x2 = 'end_time:T', \n",
    "        color = interval_type_color, \n",
    "        tooltip = ['interval_type', 'interval_value']\n",
    "    ) \n",
    "    period_dot = alt.Chart(profile_intervals).mark_square(size = 100).encode(\n",
    "        x = 'start_time:T',\n",
    "        y = alt.YValue(profile_df.value.max()),\n",
    "        color = interval_type_color, \n",
    "        tooltip = ['interval_type', 'interval_value']\n",
    "    )\n",
    "    cumulative_value_dot = alt.Chart(profile_intervals[profile_intervals.is_error == True]).mark_circle(size = 200).encode(\n",
    "        x = 'end_time:T', \n",
    "        y = '0th_value_after_end:Q',\n",
    "        color = alt.Color('is_cumulative_value:N', scale = alt.Scale(domain = [False,\"don't know\", True])), \n",
    "        tooltip = ['is_cumulative_value']\n",
    "    )\n",
    "    connection_power = profile_intervals.connection_power.iat[0]\n",
    "    pv_power = -profile_intervals.PV_power.iat[0]\n",
    "    connection_power_line = alt.Chart(pd.DataFrame({'y': [connection_power, pv_power]})).mark_rule(color = 'black', opacity = 0.8).encode(\n",
    "            y = 'y:Q'\n",
    "        )\n",
    "    period_chart = alt.layer(period_shading, period_dot).resolve_legend(color = 'shared')\n",
    "    chart = alt.layer(period_chart,cumulative_value_dot, line, connection_power_line).resolve_scale(color = 'independent').resolve_legend(color = 'independent')\n",
    "\n",
    "    return chart.properties(width = 900, height = 400,title = f\"{meterID} in {year}\").interactive()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some annotated profiles\n",
    "First of all, when the profile is 0 or NaN the background of the plot is shaded in a color that indicates the detected interval type: \n",
    "- **normal**: this is a zero interval that was detected as normal\n",
    "- **don't know**: our method is not entirely sure, when working with the profiles we will consider these intervals as normal \n",
    "- **error**: this is a zero or NaN interval due to a measurement error and thus this is missing data \n",
    "\n",
    "NaN intervals are always classified as an error, zero intervals can be classified as normal, don't know or error.  \n",
    "Because some intervals might be very narrow, squares are added at the top of the chart to show the location of the intervals. \n",
    "\n",
    "Second, when an interval is classified as an error, the next value in the timeseries gets a dot that indicates whether it is a cumulative value or not: \n",
    "- **false**: this is a normal measurement (and thus should be included)\n",
    "- **don't know**: our method is not entirely sure, when working with the profiles these values will be dropped\n",
    "- **true**: our method detects these as cumulative measurements, when working with these profiles these values should be dropped (or be interpreted as cumulative values*)\n",
    "\n",
    "Finally, the connection capacity and the negative PV_power (if known) are shown as horizontal black lines.  \n",
    "You should be able to zoom in on the charts interactively.\n",
    "\n",
    "\n",
    "*Note: the profiles shown are chosen at random*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiles with injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injection_profiles=interval_df[~interval_df.PV_power.isna()].index.get_level_values(0).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate_profile(injection_profiles[0],2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate_profile(injection_profiles[1],2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profiles with no injection but still have zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_injection_zero_profiles = interval_df[interval_df.PV_power.isna() & (interval_df.interval_value == 0)].index.get_level_values(0).to_series().value_counts().sort_values(ascending = False).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A lot of zero values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate_profile(no_injection_zero_profiles[100],2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A few zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate_profile(no_injection_zero_profiles[400], 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profiles with NaN intervals with cumulative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_intervals = intervals[intervals.interval_value.isna() & intervals.is_cumulative_value].index.get_level_values(0).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate_profile(nan_intervals[0],2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate_profile(nan_intervals[1],2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profiles with zero intervals with cumulative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_intervals = intervals[~intervals.interval_value.isna() & intervals.is_cumulative_value].index.get_level_values(0).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate_profile(zero_intervals[0],2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate_profile(zero_intervals[1],2016)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
