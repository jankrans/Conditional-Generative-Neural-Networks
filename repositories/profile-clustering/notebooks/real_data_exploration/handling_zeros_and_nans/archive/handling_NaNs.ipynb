{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The goal here is to detect connection problems in the data such that we can handle these later\n",
    "So the main idea is to look for periods where multiple meters have zero measurements, these periods are called disconnection periods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Imports and set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import datetime\n",
    "import tqdm\n",
    "idx = pd.IndexSlice\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_PATH = Path('/cw/dtaiproj/ml/2020-FLAIR-VITO/profile-clustering/preprocessed/combined')\n",
    "info_path = PRE_PATH/'info.csv'\n",
    "data_path = PRE_PATH/'data.csv'\n",
    "assert info_path.exists() and data_path.exists(), 'These paths should exist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = pd.read_csv(info_path, index_col = [0,1])\n",
    "info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(data_path, index_col = [0,1])\n",
    "data_df.columns = pd.to_datetime(data_df.columns)\n",
    "data_df.columns.name = 'timestamp'\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leap_years = [2012, 2016]\n",
    "non_leap_years = [year for year in info_df.index.levels[1] if year not in leap_years]\n",
    "print(f'leap years = {leap_years}')\n",
    "print(f'non leap years = {non_leap_years}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle all data sources and years seperately\n",
    "Of course connection problems need to be in the same year and within the same measurement project, so for now lets use the EandisVREG data of 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE = 'EandisVREG'\n",
    "YEAR = 2016\n",
    "# get the right subset based on the info df\n",
    "info16_df = info_df.loc[idx[:, 2016],:]\n",
    "info16_df = info16_df[info16_df.data_source == 'EandisVREG']\n",
    "info16_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the corresponding data profiles \n",
    "data16_df = data_df.loc[info16_df.index, :]\n",
    "data16_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the amount of NaNs and Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb of zeros for each profile\n",
    "nb_of_na = (data16_df.isna()).sum(axis = 1)\n",
    "print(f'There are {(nb_of_na>0).sum()} profiles with NaN values')\n",
    "print(f'The average number of NaNs in each these profiles is {nb_of_na[nb_of_na>0].mean()}')\n",
    "nb_of_zeros = (data16_df == 0).sum(axis = 1)\n",
    "print(f'There are {(nb_of_zeros>0).sum()} profiles with zeros values')\n",
    "print(f'The average number of zeros in each these profiles is {nb_of_zeros[nb_of_zeros>0].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(nb_of_na.value_counts().to_frame('count').reset_index().pipe(lambda x: x[x['index']>5]), title= 'histogram of amount of NaNs').mark_bar().encode(\n",
    "    x = alt.X('index:Q', title = 'amount of NaNs in profile'), \n",
    "    y = alt.Y('count:Q', title = '#profiles')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So most profiles have 4 NaN's (these are due to change from winter to summer time NOT a data problem) these are ignored in this plot and handled later.\n",
    "Profiles with the most NaN's have 1200+ NaN values, which is in total 12 days missing (we will probably be able to handle this if they are not consecutive) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(nb_of_zeros.value_counts().to_frame('count').reset_index().pipe(lambda x: x[x['index']>0]), title= 'histogram of amount of zeros').mark_bar().encode(\n",
    "    x = 'index:N', \n",
    "    y = 'count:Q'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So most profiles have no zero values (160 profiles) then we have a slight distribution around 100 zero values and then we have a very long tail  up to 35000 zero values which is almost a year of zeros (but these are still valid profiles)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at profiles with potential problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data16_df= data16_df.loc[(nb_of_na>0)| (nb_of_zeros>0), :]\n",
    "data16_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the intervals\n",
    "So in the rest of this code we simply construct the intervals as a dataset and add different attributes/features and investigate whether they could be useful or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to find intervals with only zeros\n",
    "def value_interval(meterID, year, a, value):\n",
    "    \"\"\"\n",
    "        Makes a dataframe containing the start and end of each interval (only the longest intervals) that only contains value\n",
    "    \"\"\"\n",
    "    # Create an array that is 1 where a is 0, and pad each end with an extra 0.\n",
    "    if np.isnan(value):\n",
    "        iszero = np.concatenate(([0], np.isnan(a).view(np.int8), [0]))\n",
    "    else: \n",
    "        iszero = np.concatenate(([0], np.equal(a, value).view(np.int8), [0]))\n",
    "    absdiff = np.abs(np.diff(iszero))\n",
    "    # Runs start and end where absdiff is 1.\n",
    "    ranges = np.where(absdiff == 1)[0].reshape(-1, 2)\n",
    "    df = pd.DataFrame(ranges, columns = ['start', 'end'])\n",
    "    df['meterID'] = meterID\n",
    "    df['year'] = year\n",
    "    df['interval_value'] = value\n",
    "    return df.set_index(['meterID', 'year'])\n",
    "\n",
    "def zero_nan_intervals_df(data_df): \n",
    "    dfs = []\n",
    "    for (meterID, year), row in data_df.iterrows(): \n",
    "        nan_df = value_interval( meterID, year,row, np.NaN)\n",
    "        zero_df = value_interval( meterID, year, row, 0)\n",
    "        dfs.append(nan_df)\n",
    "        dfs.append(zero_df)\n",
    "    full_df = pd.concat(dfs, axis = 0)\n",
    "#     full_df['start_time'] = data14_df.columns[full_df['start']]\n",
    "#     full_df['end_time'] = data14_df.columns[full_df['end']-1]\n",
    "    return full_df\n",
    "\n",
    "profile_intervals = zero_nan_intervals_df(data16_df)\n",
    "profile_intervals['interval_length'] = profile_intervals.end - profile_intervals.start\n",
    "# start time and end time are exclusive! (this plots well with altair that why we do it this way)\n",
    "profile_intervals['start_time'] = data16_df.columns[profile_intervals['start']] - pd.Timedelta('15min')\n",
    "profile_intervals['end_time'] = data16_df.columns[profile_intervals['end']-1] # doing it this way because the timestamp we need might not exist in the columns\n",
    "profile_intervals['end_time'] += pd.Timedelta('15min')\n",
    "profile_intervals = profile_intervals.set_index(['start', 'end'], append = True)\n",
    "profile_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*notes:*  \n",
    "- start is inclusive, end is exclusive so the interval is (start, end(  \n",
    "- start_time and end_time are both exclusive )start_time, end_time(  \n",
    "This works better for plotting in altair\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the missing hour on march 27 due to change from winter to summer time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_intervals = profile_intervals[~((profile_intervals.start_time == '2016-03-27 02:00:00') & (profile_intervals.end_time == '2016-03-27 03:00:00'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the distribution of interval length\n",
    "**NaN intervals** are mostly 3 quarters long, interestingly for the longer intervals 24 hours is a common value, same for 48 hours.  \n",
    "The longest interval is 955 (which is almost 10 days that are missing) \n",
    "\n",
    "**Zero intervals** are mostly shorter from one to ten quarters but a way longer tail! This is due to disabled meters, these are not always data problems. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_length_count = profile_intervals.reset_index().drop_duplicates(['start', 'end', 'interval_value']).groupby(['interval_value', 'interval_length'], dropna = False).size().to_frame('value').reset_index().astype({'interval_value': 'string'})\n",
    "alt.Chart(interval_length_count).mark_bar().encode(\n",
    "    x = 'interval_length:N', \n",
    "    y = 'value:Q'\n",
    ").facet(row = 'interval_value').resolve_scale(x = 'independent', y = 'independent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting function \n",
    "A plotting function that can be used to plot part of a profile with some intervals marked in different colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_profile_with_intervals(meterID, year, period_type_column = None, data = None, daterange = None):\n",
    "    # plots the profile, using the period data in data \n",
    "    # the color can be determined using the period_type_column\n",
    "    if data is None : \n",
    "        data = profile_intervals\n",
    "    if daterange is not None: \n",
    "        start_time =  f'2016-{daterange[0]}-1 00:00:00'\n",
    "        end_time = f'2016-{daterange[1]}-1 00:00:00'\n",
    "        profile_df = data16_df.loc[(meterID, year),start_time:end_time]\n",
    "        periods_for_profile =data.loc[(meterID,year), :]\n",
    "        periods_for_profile = periods_for_profile[(periods_for_profile['end_time'] > start_time ) & (periods_for_profile['start_time'] < end_time)]\n",
    "    else: \n",
    "        profile_df = data16_df.loc[(meterID, year),:]\n",
    "        periods_for_profile =data.loc[(meterID,year), :]\n",
    "        \n",
    "#     print(periods_for_profile[['start_time', 'end_time']])\n",
    "#     print(zero_periods_for_profile[['start_time', 'end_time', 'is_disconnection_period']])\n",
    "    line = alt.Chart(profile_df.to_frame('value').reset_index()).mark_line().encode(\n",
    "        x = alt.X('timestamp:T'), \n",
    "        y = alt.Y('value:Q')\n",
    "    )\n",
    "    if period_type_column is None: \n",
    "        color_encoding = alt.ColorValue('blue') \n",
    "    else: \n",
    "        color_encoding = alt.Color(f'{period_type_column}:N')\n",
    "    plot_df =periods_for_profile.reset_index(drop=True)\n",
    "    rect = alt.Chart(plot_df).mark_rect(opacity = 0.6).encode(\n",
    "        x = 'start_time:T',\n",
    "        x2 = 'end_time:T', \n",
    "        color = color_encoding\n",
    "    ) + alt.Chart(plot_df).mark_circle(opacity = 0.6).encode(\n",
    "        x = 'start_time:T',\n",
    "        y = alt.YValue(profile_df.max()),\n",
    "#         x2 = 'end_time:T', \n",
    "        color = color_encoding\n",
    "    )\n",
    "    chart = rect + line\n",
    "    if 'connection_power' in periods_for_profile.columns: \n",
    "        connection_power = float(periods_for_profile.connection_power.iat[0])\n",
    "\n",
    "        connection_power_line = alt.Chart(periods_for_profile.reset_index()).mark_rule(color = 'black', opacity = 0.8).encode(\n",
    "            y =  'mean(connection_power):Q'\n",
    "        )\n",
    "        chart += connection_power_line\n",
    "    return chart.properties(width = 2200).interactive()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add count to each interval\n",
    "Count the amount of times that each interval occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_counts = profile_intervals.reset_index().groupby(['start', 'end'])[['meterID', 'year']].size().to_frame('#profiles')\n",
    "nan_interval_counts = profile_intervals[profile_intervals.interval_value.isna()].reset_index().groupby(['start', 'end'])[['meterID', 'year']].size().to_frame('#profiles')\n",
    "zero_interval_counts = profile_intervals[~profile_intervals.interval_value.isna()].reset_index().groupby(['start', 'end'])[['meterID', 'year']].size().to_frame('#profiles')\n",
    "print(f'{len(interval_counts)} distinct disconnection periods')\n",
    "interval_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the amount of profiles that are zero during an interval and their count\n",
    "So interestingly you can see here that there are also zero intervals that occur for multiple meters! So some of these zeros are also missing values! \n",
    "It also seems that there are intervals that show up as zeros in one profile but NaNs in another profile! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chart = alt.Chart(interval_counts.reset_index(), title = '#intervals that have x profiles that are missing in the interval').mark_bar().encode(\n",
    "    x = alt.X('#profiles:N'), \n",
    "    y = alt.Y('count()')\n",
    ")\n",
    "zero_chart = alt.Chart(zero_interval_counts.reset_index(), title = '# zero intervals that have x profiles that are missing in the interval').mark_bar().encode(\n",
    "    x = alt.X('#profiles:N'), \n",
    "    y = alt.Y('count()')\n",
    ")\n",
    "nan_chart = alt.Chart(nan_interval_counts.reset_index(), title = '# NaN intervals that have x profiles that are missing in the interval').mark_bar().encode(\n",
    "    x = alt.X('#profiles:N'), \n",
    "    y = alt.Y('count()')\n",
    ")\n",
    "(all_chart & zero_chart & nan_chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if these unique missing intervals are really unique or if they are similar to one of the non-unique intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_unique(intervals): \n",
    "    df = intervals.squeeze()\n",
    "    non_unique_df = df[df > 1]\n",
    "    unique_df = df[df == 1]\n",
    "    non_unique_set = {index for index in non_unique_df.index}\n",
    "    remaining_uniques = []\n",
    "    for start, end in unique_df.index: \n",
    "        found = False\n",
    "        for delta_s, delta_e in itertools.product([-1, 0,1], [-1, 0, 1]): \n",
    "            if (start + delta_s, end + delta_e) in non_unique_set: \n",
    "                found = True\n",
    "                break\n",
    "        if not found: \n",
    "            remaining_uniques.append((start,end))\n",
    "    return remaining_uniques\n",
    "unique_nans = check_unique(nan_interval_counts)\n",
    "unique_zeros = check_unique(zero_interval_counts)\n",
    "print(f'there are {len(unique_nans)} unique NaN intervals that are not similar to a more common NaN interval (of {len(nan_interval_counts[nan_interval_counts.squeeze()==1])} unique intervals)')\n",
    "print(f'there are {len(unique_zeros)} unique zero intervals that are not similar to a more common zero interval (of {len(zero_interval_counts[zero_interval_counts.squeeze() == 1])} unique intervals)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = nan_interval_counts.loc[unique_nans].reset_index().eval('end-start').to_frame('interval_length')\n",
    "temp = temp.value_counts().sort_index().to_frame('count').reset_index()\n",
    "alt.Chart(temp, title = 'histogram of the length of the unique profiles').mark_bar().encode(\n",
    "    x = alt.X('interval_length:N', title = 'Interval length'), \n",
    "    y = alt.Y('count:Q', title = '# unique profiles of given length')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this shows that there are intervals that are not similar to any other interval but are still measurement errors.  \n",
    "We can also see that the length of these unique periods is not necesarrily short intervals.  \n",
    "**In conclusion, a high count can be indicative of measurement errors but a low count does not necessarily mean that it is a valid measurement.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if there are intervals that show up as zero and as NaN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intervals that occur twice, occur once as a zero interval and once as a nan interval\n",
    "zero_nan_intervals = profile_intervals.reset_index()[['start', 'end', 'interval_value']].drop_duplicates().groupby(['start', 'end']).size() == 2\n",
    "zero_nan_intervals = zero_nan_intervals.index[zero_nan_intervals].to_frame(index = False)\n",
    "zero_nan_intervals['length'] = zero_nan_intervals['end'] - zero_nan_intervals['start']\n",
    "zero_nan_intervals['length'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there clearly are intervals that occur both as a zero interval and as a nan interval!  \n",
    "The lengths of these intervals are also not necessarily short (although short intervals are more common)  \n",
    "This makes me think that there is some weird preprocessing involved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = zero_nan_intervals.set_index(['start', 'end']).join(profile_intervals.reset_index().set_index(['start', 'end', 'meterID', 'year']), how = 'inner' )\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//TODO visualize some of these co-occurences? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the length of each interval vs its count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_vs_count_scatter_plot(df): \n",
    "    df = df.reset_index()\n",
    "    df['length'] = df['end'] - df['start']\n",
    "    return alt.Chart(df).mark_circle().encode(\n",
    "        x = '#profiles:N', \n",
    "        y = alt.Y('length:Q', scale = alt.Scale(type = 'log'))\n",
    "    )\n",
    "length_vs_count_scatter_plot(interval_counts).properties(title = 'all') & length_vs_count_scatter_plot(zero_interval_counts).properties(title = 'zero') & length_vs_count_scatter_plot(nan_interval_counts).properties(title = 'NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, most of these intervals are unique (there is only one meter that is zero/NaN in this interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add this info to profile_intervals\n",
    "if '#profiles' not in profile_intervals.columns: \n",
    "    profile_intervals = profile_intervals.join(interval_counts, on = ['start', 'end'])\n",
    "profile_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if we can distinguish NaN intervals from 0 intervals\n",
    "We'll use a decision tree to check if we can learn a function that figures out if a certain interval is zero or NaN given the other features (learned this trick from Elia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt # I don't want to :( but I have to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth = 3)\n",
    "y = profile_intervals['interval_value'].fillna(1).astype('int').values\n",
    "X = profile_intervals.reset_index().drop(columns = ['meterID', 'year', 'interval_value', 'start_time', 'end_time'])\n",
    "tree.fit(X.values,y)\n",
    "plt.figure(figsize = (20,10))\n",
    "plot_tree(tree, feature_names = X.columns);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I played around a little bit with this but nothing to conclude, they are not perfectly seperable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check NaN interval stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_intervals[profile_intervals.interval_value.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the intervals with counts > 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_high_count = profile_intervals[profile_intervals['#profiles']> 600]\n",
    "very_high_count_ids = very_high_count.index.to_frame(index = False)\n",
    "very_high_count[['start_time','end_time']].drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = profile_intervals.copy()\n",
    "temp_df['high_count'] = temp_df['#profiles'] > 600\n",
    "temp_df\n",
    "\n",
    "plot_profile_with_intervals(*very_high_count_ids.iloc[0,:2], 'high_count', data = temp_df, daterange = (1,4)) & plot_profile_with_intervals(*very_high_count_ids.iloc[3,:2], 'high_count', data = temp_df, daterange = (1,4))\n",
    "# plot_profile_with_intervals(*very_high_count_ids.iloc[3,:2], 'high_count', data = temp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate intervals with counts > 10 and < 35  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_count = profile_intervals[(profile_intervals['#profiles']> 10) & (profile_intervals['#profiles'] < 35)]\n",
    "high_count_ids = high_count.index.to_frame(index = False)\n",
    "intervals_of_interest = high_count.drop_duplicates(['start_time', 'end_time', 'interval_value']).sort_values(['start_time', 'end_time']).reset_index(drop = True)\n",
    "intervals_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_of_interest.interval_length.value_counts().to_frame('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_of_interest.interval_value.value_counts(dropna=False).to_frame('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = profile_intervals.copy()\n",
    "temp_df['high_count'] = (temp_df['#profiles'] > 10)&(temp_df['#profiles'] < 35)\n",
    "temp_df\n",
    "\n",
    "plot_profile_with_intervals(*high_count_ids.iloc[0,:2], 'high_count', data = temp_df) & plot_profile_with_intervals(*high_count_ids.iloc[3,:2], 'high_count', data = temp_df)\n",
    "# plot_profile_with_intervals(*very_high_count_ids.iloc[3,:2], 'high_count', data = temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add value before and after each interval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data16_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile_intervals['value_after_interval'] =\n",
    "def value_after_end(row):\n",
    "    meterID, year, start, end = row.name\n",
    "    # if end is to large\n",
    "    if end == 35136:\n",
    "        return 'end'\n",
    "    value = data16_df.at[(meterID,year), data16_df.columns[end]]\n",
    "    return value\n",
    "def value_before_start(row): \n",
    "    meterID, year, start, end = row.name\n",
    "    # if end is to large\n",
    "    if start == 0:\n",
    "        return 'start'\n",
    "    return data16_df.at[(meterID, year), data16_df.columns[start - 1]]\n",
    "# if 'value_after_interval' not in profile_intervals.columns: \n",
    "\n",
    "profile_intervals['value_after_interval'] = profile_intervals.apply(value_after_end, axis = 1)\n",
    "profile_intervals['value_before_interval'] = profile_intervals.apply(value_before_start, axis = 1)\n",
    "profile_intervals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add connection capacity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_intervals = profile_intervals.drop(columns = ['connection_power'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'connection_power' not in profile_intervals.columns:\n",
    "    connection_power = info16_df[['connection_power']]\n",
    "    profile_intervals = profile_intervals.join(connection_power)\n",
    "profile_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check peaks due to connection_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'connection_power_peak' not in profile_intervals.columns: \n",
    "    profile_intervals['connection_power_peak'] = profile_intervals['value_after_interval'].replace({'end': np.NaN}) > profile_intervals['connection_power'].astype('float')\n",
    "profile_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_intervals.connection_power_peak.value_counts().to_frame('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So clearly this rule only helps to detect very few peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's look a bit deeper at profiles with lots of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_intervals = profile_intervals.query('interval_value == 0')\n",
    "zero_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's inspect the results by plotting them\n",
    "So this is not clean anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_intervals_with_zero_followed_by_nan = profile_intervals[(profile_intervals.interval_value == 0)&(profile_intervals.value_after_interval.isna()) ]\n",
    "profile_intervals_with_zero_followed_by_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_with_long_intervals = zero_intervals.index[zero_intervals.interval_length > 4].unique().to_list()\n",
    "long_zero_intervals = zero_intervals.loc[profiles_with_long_intervals, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_profile_with_period_marks(long_zero_intervals.index[-100], data = long_zero_intervals )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data16_df.loc[long_zero_intervals.index[-100]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(plot_profile_with_period_marks(2) & plot_profile_with_period_marks(3)).resolve_scale(x = 'shared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
