{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distinguish measurement errors from real zero measurements\n",
    "\n",
    "So we build upon a couple of intuitions.  \n",
    "Indicators for an error: \n",
    "- clear cumulative value \n",
    "- collective zero/NaN interval (it happens that in one profile an interval is zero and in another it is NaN) \n",
    "- a zero interval in a profile where zeros are exceptional \n",
    "\n",
    "Indicators for normal behaviour: \n",
    "- Profiles where zeros are common (and no other indications of an error) \n",
    "- **A single zero when there is a consumption sign change**  *Implemented*\n",
    "- consumption around zero interval is low \n",
    "- Very long zero intervals (if not followed by a cumulative value) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Imports and set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import datetime\n",
    "import tqdm\n",
    "idx = pd.IndexSlice\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interval_information import get_interval_df\n",
    "from peak_detection import (\n",
    "    get_cumulative_value_detections, \n",
    "    get_connection_and_pv_power_peaks, \n",
    "    get_knn_similarity_based_peaks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_PATH = Path('/cw/dtaiproj/ml/2020-FLAIR-VITO/profile-clustering/preprocessed/combined')\n",
    "info_path = PRE_PATH/'info.csv'\n",
    "data_path = PRE_PATH/'data.csv'\n",
    "assert info_path.exists() and data_path.exists(), 'These paths should exist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_profile_with_intervals(meterID, year, period_type_column = None, data = None, daterange = None):\n",
    "    # plots the profile, using the period data in data \n",
    "    # the color can be determined using the period_type_column\n",
    "    if data is None : \n",
    "        data = nan_intervals\n",
    "    if daterange is not None: \n",
    "        start_time =  f'2016-{daterange[0]}-1 00:00:00'\n",
    "        end_time = f'2016-{daterange[1]}-1 00:00:00'\n",
    "        profile_df = data16_df.loc[(meterID, year),start_time:end_time]\n",
    "        periods_for_profile =data.loc[(meterID,year), :]\n",
    "        periods_for_profile = periods_for_profile[(periods_for_profile['end_time'] > start_time ) & (periods_for_profile['start_time'] < end_time)]\n",
    "    else: \n",
    "        profile_df = data16_df.loc[(meterID, year),:]\n",
    "        periods_for_profile =data.loc[(meterID,year), :]\n",
    "        \n",
    "#     print(periods_for_profile[['start_time', 'end_time']])\n",
    "#     print(zero_periods_for_profile[['start_time', 'end_time', 'is_disconnection_period']])\n",
    "    line = alt.Chart(profile_df.to_frame('value').reset_index()).mark_line().encode(\n",
    "        x = alt.X('timestamp:T'), \n",
    "        y = alt.Y('value:Q')\n",
    "    )\n",
    "    if period_type_column is None: \n",
    "        color_encoding = alt.ColorValue('blue') \n",
    "    else: \n",
    "        color_encoding = alt.Color(f'{period_type_column}:N')\n",
    "    plot_df =periods_for_profile.reset_index(drop=True)\n",
    "    rect = alt.Chart(plot_df).mark_rect(opacity = 0.6).encode(\n",
    "        x = 'start_time:T',\n",
    "        x2 = 'end_time:T', \n",
    "        color = color_encoding\n",
    "    ) + alt.Chart(plot_df).mark_circle(opacity = 0.6).encode(\n",
    "        x = 'start_time:T',\n",
    "        y = alt.YValue(profile_df.max()),\n",
    "#         x2 = 'end_time:T', \n",
    "        color = color_encoding\n",
    "    )\n",
    "    chart = rect + line\n",
    "    if 'connection_power' in periods_for_profile.columns: \n",
    "        connection_power = float(periods_for_profile.connection_power.iat[0])\n",
    "\n",
    "        connection_power_line = alt.Chart(periods_for_profile.reset_index()).mark_rule(color = 'black', opacity = 0.8).encode(\n",
    "            y =  'mean(connection_power):Q'\n",
    "        )\n",
    "        chart += connection_power_line\n",
    "    return chart.properties(width = 2200, title = f\"{meterID} in {year}\").interactive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(name1, series1, name2, series2): \n",
    "    return pd.crosstab(series1, series2, rownames = [name1], colnames =[name2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = pd.read_csv(info_path, index_col = [0,1])\n",
    "data_df = pd.read_csv(data_path, index_col = [0,1])\n",
    "data_df.columns = pd.to_datetime(data_df.columns)\n",
    "data_df.columns.name = 'timestamp'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle all data sources and years seperately\n",
    "Of course connection problems need to be in the same year and within the same measurement project, so for now lets use the EandisVREG data of 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE = 'EandisVREG'\n",
    "YEAR = 2016\n",
    "# get the right subset based on the info df\n",
    "info16_df = info_df.loc[idx[:, 2016],:]\n",
    "info16_df = info16_df[info16_df.data_source == 'EandisVREG']\n",
    "\n",
    "# read the corresponding data profiles \n",
    "data16_df = data_df.loc[info16_df.index, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For this only look at the profiles that have zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb of zeros for each profile\n",
    "nb_of_zeros = (data16_df == 0).sum(axis = 1)\n",
    "nb_of_nan = data16_df.isna().any(axis =1 )\n",
    "data16_df= data16_df.loc[(nb_of_zeros>0) | nb_of_nan]\n",
    "data16_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the intervals\n",
    "So in the rest of this code we simply construct the intervals as a dataset and add different attributes/features and investigate whether they could be useful or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "interval_df = get_interval_df(data16_df, info16_df, keep_zero = True, keep_nan = True)\n",
    "interval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a small subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_OF_PROFILES = 100\n",
    "profile_sample = interval_df.index.get_level_values(0).unique()[:NB_OF_PROFILES]\n",
    "interval2_df = interval_df.loc[profile_sample]\n",
    "interval2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill this df with detection information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_df = pd.DataFrame(index = interval2_df.index)\n",
    "detection_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_zero_intervals = (\n",
    "    interval2_df\n",
    "    .replace({'start':np.nan, 'end': np.nan})\n",
    "    .dropna(subset = ['0th_value_after_end', 'value_before_start'])\n",
    "    .query('interval_value == 0')\n",
    "    .query('interval_length == 1')\n",
    ")\n",
    "# short_zero_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_change_intervals = np.sign(short_zero_intervals['value_before_start']) == - np.sign(short_zero_intervals['0th_value_after_end'])\n",
    "count = sign_change_intervals.value_counts(dropna = False).to_frame('count')\n",
    "count['relative_count'] = count['count']/count['count'].sum()\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add to detection df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_df['sign_change'] = np.nan\n",
    "detection_df.loc[sign_change_intervals[sign_change_intervals].index, 'sign_change'] = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A single zero with low consumption on both sides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_low_consumption = (short_zero_intervals['value_before_start'] < 0.1) & (short_zero_intervals['0th_value_after_end'] < 0.1)\n",
    "count = short_low_consumption.value_counts(dropna = False).to_frame('count')\n",
    "count['relative_count'] = count['count']/count['count'].sum()\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion with sign change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix('low_consumption', short_low_consumption, 'sign_change', sign_change_intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add to detection df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_df['short_low_consumption'] = np.nan\n",
    "detection_df.loc[short_low_consumption[short_low_consumption].index, 'short_low_consumption'] = False\n",
    "detection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_df = detection_df.drop(columns = 'detection')\n",
    "detected_normal = (detection_df == False).any(axis = 1)\n",
    "detected_cumulative = (detection_df == True).any(axis =1)\n",
    "detection_df['detection'] = np.nan\n",
    "detection_df.loc[detected_normal, 'detection'] = False\n",
    "detection_df.loc[detected_cumulative, 'detection'] = True \n",
    "detection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_intervals = interval2_df[detection_df.detection.isna()]\n",
    "remaining_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cumulative value detection on the zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection power peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_power_peaks = get_connection_and_pv_power_peaks(remaining_intervals)\n",
    "connection_power_peaks.value_counts().to_frame('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_intervals[connection_power_peaks].interval_value.value_counts(dropna= False).to_frame('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add to detection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_df['connection_power'] = np.nan\n",
    "detection_df.loc[connection_power_peaks[connection_power_peaks].index, 'connection_power'] = True\n",
    "detection_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity based peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "same_day_intervals = remaining_intervals[remaining_intervals.start_time.dt.date == remaining_intervals.end_time.dt.date]\n",
    "avoid_bug = same_day_intervals[(same_day_intervals.start_time - pd.Timedelta('3H')).dt.date == same_day_intervals.start_time.dt.date]\n",
    "\n",
    "similarity_peaks = get_knn_similarity_based_peaks(data16_df, avoid_bug, 50,'6H',  5)\n",
    "similarity_peaks.value_counts(dropna =False).to_frame('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_df['similarity'] = np.nan\n",
    "detection_df.loc[similarity_peaks.index, 'similarity'] = similarity_peaks\n",
    "detection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_normal = (detection_df[['sign_change', 'short_low_consumption']] == False).any(axis = 1)\n",
    "detected_cumulative = (detection_df[['sign_change', 'short_low_consumption']] == True).any(axis =1)\n",
    "detection_df['intuitions'] = np.nan\n",
    "detection_df.loc[detected_normal, 'intuitions'] = False\n",
    "detection_df.loc[detected_cumulative, 'intuitions'] = True \n",
    "detection_df\n",
    "\n",
    "detections = detection_df.intuitions\n",
    "detections[detections.isna()] = detection_df.connection_power[detections.isna()]\n",
    "detections[detections.isna()] = detection_df.similarity[detections.isna()]\n",
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_true = (similarity_peaks == True).index.get_level_values(0).unique()\n",
    "vis_df = interval_df.join(detections.fillna('no_detection').to_frame('cumulative'))\n",
    "IDX = 1 \n",
    "plot_profile_with_intervals(detection_true[IDX],2016, period_type_column = 'cumulative', data = vis_df, daterange = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intuition: if the zero values are very uncommon using a kde the zeros are probably measurement mistakes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise beforehand to get some good examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_sorted_by_zero_count = (data16_df == 0).sum(axis = 1).sort_values().index.get_level_values(0)\n",
    "profiles_sorted_by_zero_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 100\n",
    "plot_profile_with_intervals(profiles_sorted_by_zero_count[IDX], 2016, data = interval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third intuition: very long zero periods are disabled meters not measurement errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea let's check how long the longest NaN intervals are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_intervals = full_interval_df[full_interval_df.interval_value.isna()]\n",
    "nan_intervals\n",
    "zero_intervals = full_interval_df[full_interval_df.interval_value == 0]\n",
    "zero_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = nan_intervals.interval_length.value_counts().to_frame('count')\n",
    "nan_interval_length = alt.Chart(temp.reset_index(), title = 'NaN interval length').mark_bar().encode(\n",
    "    x = 'index:N',\n",
    "    y= 'count'\n",
    ")\n",
    "temp = zero_intervals.interval_length.value_counts().to_frame('count')\n",
    "zero_interval_length = alt.Chart(temp[temp.index<200].reset_index(), title = 'zero interval length').mark_bar().encode(\n",
    "    x = 'index:Q',\n",
    "    y= 'count'\n",
    ")\n",
    "(nan_interval_length | zero_interval_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the longest NaN interval is 200 but the zero intervals are way longer. So everything longer than 200 timestamps +- 2 days is considered a disabled meter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_zero_intervals = zero_intervals[zero_intervals.interval_length > 200]\n",
    "long_zero_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_intervals.loc[long_zero_intervals.index, 'interval_type'] = 'real_long_disabled_meter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_profiles = long_zero_intervals.index.get_level_values(0).unique()\n",
    "INDEX = 25\n",
    "print(f'showing profile {INDEX} from {len(relevant_profiles)}')\n",
    "print(relevant_profiles[INDEX])\n",
    "plot_profile_with_intervals(relevant_profiles[INDEX], 2016, 'interval_type', data = zero_intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again show some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add count to each interval\n",
    "Count the amount of times that each interval occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_counts = profile_intervals.reset_index().groupby(['start', 'end'])[['meterID', 'year']].size().to_frame('#profiles')\n",
    "nan_interval_counts = profile_intervals[profile_intervals.interval_value.isna()].reset_index().groupby(['start', 'end'])[['meterID', 'year']].size().to_frame('#profiles')\n",
    "zero_interval_counts = profile_intervals[~profile_intervals.interval_value.isna()].reset_index().groupby(['start', 'end'])[['meterID', 'year']].size().to_frame('#profiles')\n",
    "print(f'{len(interval_counts)} distinct disconnection periods')\n",
    "interval_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the amount of profiles that are zero during an interval and their count\n",
    "So interestingly you can see here that there are also zero intervals that occur for multiple meters! So some of these zeros are also missing values! \n",
    "It also seems that there are intervals that show up as zeros in one profile but NaNs in another profile! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chart = alt.Chart(interval_counts.reset_index(), title = '#intervals that have x profiles that are missing in the interval').mark_bar().encode(\n",
    "    x = alt.X('#profiles:N'), \n",
    "    y = alt.Y('count()')\n",
    ")\n",
    "zero_chart = alt.Chart(zero_interval_counts.reset_index(), title = '# zero intervals that have x profiles that are missing in the interval').mark_bar().encode(\n",
    "    x = alt.X('#profiles:N'), \n",
    "    y = alt.Y('count()')\n",
    ")\n",
    "nan_chart = alt.Chart(nan_interval_counts.reset_index(), title = '# NaN intervals that have x profiles that are missing in the interval').mark_bar().encode(\n",
    "    x = alt.X('#profiles:N'), \n",
    "    y = alt.Y('count()')\n",
    ")\n",
    "(all_chart & zero_chart & nan_chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if these unique missing intervals are really unique or if they are similar to one of the non-unique intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_unique(intervals): \n",
    "    df = intervals.squeeze()\n",
    "    non_unique_df = df[df > 1]\n",
    "    unique_df = df[df == 1]\n",
    "    non_unique_set = {index for index in non_unique_df.index}\n",
    "    remaining_uniques = []\n",
    "    for start, end in unique_df.index: \n",
    "        found = False\n",
    "        for delta_s, delta_e in itertools.product([-1, 0,1], [-1, 0, 1]): \n",
    "            if (start + delta_s, end + delta_e) in non_unique_set: \n",
    "                found = True\n",
    "                break\n",
    "        if not found: \n",
    "            remaining_uniques.append((start,end))\n",
    "    return remaining_uniques\n",
    "unique_nans = check_unique(nan_interval_counts)\n",
    "unique_zeros = check_unique(zero_interval_counts)\n",
    "print(f'there are {len(unique_nans)} unique NaN intervals that are not similar to a more common NaN interval (of {len(nan_interval_counts[nan_interval_counts.squeeze()==1])} unique intervals)')\n",
    "print(f'there are {len(unique_zeros)} unique zero intervals that are not similar to a more common zero interval (of {len(zero_interval_counts[zero_interval_counts.squeeze() == 1])} unique intervals)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = nan_interval_counts.loc[unique_nans].reset_index().eval('end-start').to_frame('interval_length')\n",
    "temp = temp.value_counts().sort_index().to_frame('count').reset_index()\n",
    "alt.Chart(temp, title = 'histogram of the length of the unique profiles').mark_bar().encode(\n",
    "    x = alt.X('interval_length:N', title = 'Interval length'), \n",
    "    y = alt.Y('count:Q', title = '# unique profiles of given length')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this shows that there are intervals that are not similar to any other interval but are still measurement errors.  \n",
    "We can also see that the length of these unique periods is not necesarrily short intervals.  \n",
    "**In conclusion, a high count can be indicative of measurement errors but a low count does not necessarily mean that it is a valid measurement.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if there are intervals that show up as zero and as NaN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intervals that occur twice, occur once as a zero interval and once as a nan interval\n",
    "zero_nan_intervals = profile_intervals.reset_index()[['start', 'end', 'interval_value']].drop_duplicates().groupby(['start', 'end']).size() == 2\n",
    "zero_nan_intervals = zero_nan_intervals.index[zero_nan_intervals].to_frame(index = False)\n",
    "zero_nan_intervals['length'] = zero_nan_intervals['end'] - zero_nan_intervals['start']\n",
    "zero_nan_intervals['length'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there clearly are intervals that occur both as a zero interval and as a nan interval!  \n",
    "The lengths of these intervals are also not necessarily short (although short intervals are more common)  \n",
    "This makes me think that there is some weird preprocessing involved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = zero_nan_intervals.set_index(['start', 'end']).join(profile_intervals.reset_index().set_index(['start', 'end', 'meterID', 'year']), how = 'inner' )\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//TODO visualize some of these co-occurences? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the length of each interval vs its count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_vs_count_scatter_plot(df): \n",
    "    df = df.reset_index()\n",
    "    df['length'] = df['end'] - df['start']\n",
    "    return alt.Chart(df).mark_circle().encode(\n",
    "        x = '#profiles:N', \n",
    "        y = alt.Y('length:Q', scale = alt.Scale(type = 'log'))\n",
    "    )\n",
    "length_vs_count_scatter_plot(interval_counts).properties(title = 'all') & length_vs_count_scatter_plot(zero_interval_counts).properties(title = 'zero') & length_vs_count_scatter_plot(nan_interval_counts).properties(title = 'NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, most of these intervals are unique (there is only one meter that is zero/NaN in this interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add this info to profile_intervals\n",
    "if '#profiles' not in profile_intervals.columns: \n",
    "    profile_intervals = profile_intervals.join(interval_counts, on = ['start', 'end'])\n",
    "profile_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if we can distinguish NaN intervals from 0 intervals\n",
    "We'll use a decision tree to check if we can learn a function that figures out if a certain interval is zero or NaN given the other features (learned this trick from Elia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt # I don't want to :( but I have to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth = 3)\n",
    "y = profile_intervals['interval_value'].fillna(1).astype('int').values\n",
    "X = profile_intervals.reset_index().drop(columns = ['meterID', 'year', 'interval_value', 'start_time', 'end_time'])\n",
    "tree.fit(X.values,y)\n",
    "plt.figure(figsize = (20,10))\n",
    "plot_tree(tree, feature_names = X.columns);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I played around a little bit with this but nothing to conclude, they are not perfectly seperable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check NaN interval stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_intervals[profile_intervals.interval_value.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the intervals with counts > 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_high_count = profile_intervals[profile_intervals['#profiles']> 600]\n",
    "very_high_count_ids = very_high_count.index.to_frame(index = False)\n",
    "very_high_count[['start_time','end_time']].drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = profile_intervals.copy()\n",
    "temp_df['high_count'] = temp_df['#profiles'] > 600\n",
    "temp_df\n",
    "\n",
    "plot_profile_with_intervals(*very_high_count_ids.iloc[0,:2], 'high_count', data = temp_df, daterange = (1,4)) & plot_profile_with_intervals(*very_high_count_ids.iloc[3,:2], 'high_count', data = temp_df, daterange = (1,4))\n",
    "# plot_profile_with_intervals(*very_high_count_ids.iloc[3,:2], 'high_count', data = temp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate intervals with counts > 10 and < 35  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_count = profile_intervals[(profile_intervals['#profiles']> 10) & (profile_intervals['#profiles'] < 35)]\n",
    "high_count_ids = high_count.index.to_frame(index = False)\n",
    "intervals_of_interest = high_count.drop_duplicates(['start_time', 'end_time', 'interval_value']).sort_values(['start_time', 'end_time']).reset_index(drop = True)\n",
    "intervals_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_of_interest.interval_length.value_counts().to_frame('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_of_interest.interval_value.value_counts(dropna=False).to_frame('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = profile_intervals.copy()\n",
    "temp_df['high_count'] = (temp_df['#profiles'] > 10)&(temp_df['#profiles'] < 35)\n",
    "temp_df\n",
    "\n",
    "plot_profile_with_intervals(*high_count_ids.iloc[0,:2], 'high_count', data = temp_df) & plot_profile_with_intervals(*high_count_ids.iloc[3,:2], 'high_count', data = temp_df)\n",
    "# plot_profile_with_intervals(*very_high_count_ids.iloc[3,:2], 'high_count', data = temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add value before and after each interval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data16_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile_intervals['value_after_interval'] =\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add connection capacity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_intervals = profile_intervals.drop(columns = ['connection_power'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'connection_power' not in profile_intervals.columns:\n",
    "    connection_power = info16_df[['connection_power']]\n",
    "    profile_intervals = profile_intervals.join(connection_power)\n",
    "profile_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check peaks due to connection_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'connection_power_peak' not in profile_intervals.columns: \n",
    "    profile_intervals['connection_power_peak'] = profile_intervals['value_after_interval'].replace({'end': np.NaN}) > profile_intervals['connection_power'].astype('float')\n",
    "profile_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_intervals.connection_power_peak.value_counts().to_frame('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So clearly this rule only helps to detect very few peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's look a bit deeper at profiles with lots of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_intervals = profile_intervals.query('interval_value == 0')\n",
    "zero_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's inspect the results by plotting them\n",
    "So this is not clean anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_intervals_with_zero_followed_by_nan = profile_intervals[(profile_intervals.interval_value == 0)&(profile_intervals.value_after_interval.isna()) ]\n",
    "profile_intervals_with_zero_followed_by_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_with_long_intervals = zero_intervals.index[zero_intervals.interval_length > 4].unique().to_list()\n",
    "long_zero_intervals = zero_intervals.loc[profiles_with_long_intervals, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_profile_with_period_marks(long_zero_intervals.index[-100], data = long_zero_intervals )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data16_df.loc[long_zero_intervals.index[-100]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(plot_profile_with_period_marks(2) & plot_profile_with_period_marks(3)).resolve_scale(x = 'shared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
