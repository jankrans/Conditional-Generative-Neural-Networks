{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Imports and set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd #conda install dask\n",
    "from dask.distributed import Client\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import datetime\n",
    "import tqdm\n",
    "idx = pd.IndexSlice\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interval_information import get_interval_df\n",
    "from peak_detection import (\n",
    "    get_cumulative_value_detections, \n",
    "    get_connection_and_pv_power_peaks, \n",
    "    get_knn_similarity_based_peaks,\n",
    "    match_knn_then_assumption_parallel\n",
    ")\n",
    "from zero_intervals import (\n",
    "    sign_change_intervals, \n",
    "    low_consumption_on_both_sides_intervals\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_PATH = Path('/cw/dtaiproj/ml/2020-FLAIR-VITO/profile-clustering/preprocessed/combined')\n",
    "RESULT_PATH = Path('/cw/dtaiproj/ml/2020-FLAIR-VITO/profile-clustering/cumulative_value_detection')\n",
    "info_path = PRE_PATH/'info.csv'\n",
    "data_path = PRE_PATH/'data.csv'\n",
    "assert info_path.exists() and data_path.exists(), 'These paths should exist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_intervals(meterID, year, start_time, context = '10D'): \n",
    "    subset = data16_df.loc[meterID]\n",
    "    line = alt.Chart(subset).mark_line().encode(\n",
    "        x = 'timestamp:T', \n",
    "        y = 'value', \n",
    "        color = 'meterID'\n",
    "    )\n",
    "    return line.properties(width = 2200).interactive(bind_y = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_profile_with_intervals(meterID, year, period_type_column = None, data = None, daterange = None):\n",
    "    # plots the profile, using the period data in data \n",
    "    # the color can be determined using the period_type_column\n",
    "    if data is None : \n",
    "        data = nan_intervals\n",
    "    if daterange is not None: \n",
    "        start_time =  f'2016-{daterange[0]}-1 00:00:00'\n",
    "        end_time = f'2016-{daterange[1]}-1 00:00:00'\n",
    "        profile_df = data16_df.loc[(meterID, year),start_time:end_time]\n",
    "        periods_for_profile =data.loc[(meterID,year), :]\n",
    "        periods_for_profile = periods_for_profile[(periods_for_profile['end_time'] > start_time ) & (periods_for_profile['start_time'] < end_time)]\n",
    "    else: \n",
    "        profile_df = data16_df.loc[(meterID, year),:]\n",
    "        periods_for_profile =data.loc[(meterID,year), :]\n",
    "        \n",
    "#     print(periods_for_profile[['start_time', 'end_time']])\n",
    "#     print(zero_periods_for_profile[['start_time', 'end_time', 'is_disconnection_period']])\n",
    "    line = alt.Chart(profile_df.to_frame('value').reset_index()).mark_line().encode(\n",
    "        x = alt.X('timestamp:T'), \n",
    "        y = alt.Y('value:Q')\n",
    "    )\n",
    "    if period_type_column is None: \n",
    "        color_encoding = alt.ColorValue('blue') \n",
    "    else: \n",
    "        color_encoding = alt.Color(f'{period_type_column}:N')\n",
    "    plot_df =periods_for_profile.reset_index(drop=True)\n",
    "    rect = alt.Chart(plot_df).mark_rect(opacity = 0.6).encode(\n",
    "        x = 'start_time:T',\n",
    "        x2 = 'end_time:T', \n",
    "        color = color_encoding\n",
    "    ) + alt.Chart(plot_df).mark_circle(opacity = 0.6).encode(\n",
    "        x = 'start_time:T',\n",
    "        y = alt.YValue(profile_df.max()),\n",
    "#         x2 = 'end_time:T', \n",
    "        color = color_encoding\n",
    "    )\n",
    "    chart = rect + line\n",
    "    if 'connection_power' in periods_for_profile.columns: \n",
    "        connection_power = float(periods_for_profile.connection_power.iat[0])\n",
    "\n",
    "        connection_power_line = alt.Chart(periods_for_profile.reset_index()).mark_rule(color = 'black', opacity = 0.8).encode(\n",
    "            y =  'mean(connection_power):Q'\n",
    "        )\n",
    "        chart += connection_power_line\n",
    "    return chart.properties(width = 2200, title = f\"{meterID} in {year}\").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(name1, series1, name2, series2): \n",
    "    return pd.crosstab(series1, series2, rownames = [name1], colnames =[name2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_summary(series): \n",
    "    count = series.value_counts(dropna=False).to_frame('count')\n",
    "    count['relative'] = count['count']/count['count'].sum()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_strategies(*args): \n",
    "    strategies = pd.concat(args, axis = 1)\n",
    "    normal = (strategies == False).any(axis = 1)\n",
    "    error = (strategies == True).any(axis = 1)\n",
    "    nan = (strategies.isna()).all(axis = 1)\n",
    "    result = pd.Series(index = strategies.index, dtype ='object')\n",
    "    result[error] = True\n",
    "    result[normal] = False\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = pd.read_csv(info_path, index_col = [0,1])\n",
    "data_df = pd.read_csv(data_path, index_col = [0,1])\n",
    "data_df.columns = pd.to_datetime(data_df.columns)\n",
    "data_df.columns.name = 'timestamp'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE = 'EandisVREG'\n",
    "YEAR = 2016\n",
    "# get the right subset based on the info df\n",
    "info16_df = info_df.loc[idx[:, 2016],:]\n",
    "info16_df = info16_df[info16_df.data_source == 'EandisVREG']\n",
    "\n",
    "# read the corresponding data profiles \n",
    "data16_df = data_df.loc[info16_df.index, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only investigate timeseries with data problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb of zeros for each profile\n",
    "nb_of_zeros = (data16_df == 0).sum(axis = 1)\n",
    "nb_of_nan = data16_df.isna().any(axis =1 )\n",
    "data16_df= data16_df.loc[(nb_of_zeros>0) | nb_of_nan]\n",
    "# data16_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the intervals\n",
    "So in the rest of this code we simply construct the intervals as a dataset and add different attributes/features and investigate whether they could be useful or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "interval_df = get_interval_df(data16_df, info16_df, keep_zero = True, keep_nan = True)\n",
    "interval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collective periods based on start time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_detection = combine_strategies(low_consumption_detection, sign_change_detection)\n",
    "detection_summary(current_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't look at the intervals we have marked as normal already\n",
    "rel_interval_df = interval_df[current_detection != False]\n",
    "rel_interval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how much each start time occurs\n",
    "interval_counts = rel_interval_df.reset_index().groupby('start')[['meterID', 'year']].size()\n",
    "# add this to the interval df as a column\n",
    "intervals_with_count = rel_interval_df.join(interval_counts.to_frame('count'), on = ['start'])\n",
    "\n",
    "# only use the intervals with a very high count\n",
    "intervals_with_count = intervals_with_count[intervals_with_count['count'] >= 33] \n",
    "\n",
    "# filter each group of intervals that start on the same moment, only allow intervals with the most common length +- a threshold (in this case 2)\n",
    "def filter_groups(df): \n",
    "    THRESHOLD = 2\n",
    "    most_common_value = df.interval_length.value_counts().idxmax()\n",
    "    return df[(df.interval_length >= most_common_value -THRESHOLD) & (df.interval_length <= most_common_value + THRESHOLD) ]\n",
    "intervals_with_count = intervals_with_count.groupby('start_time').apply(filter_groups).droplevel(0)\n",
    "# each of the intervals that remains is thus a collective data problem and is a data error\n",
    "collective_data_problems  = pd.Series(index = interval_df.index, dtype = 'object')\n",
    "collective_data_problems.loc[intervals_with_count.index] = True\n",
    "detection_summary(collective_data_problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_result = combine_strategies(sign_change_detection,low_consumption_detection, collective_data_problems)\n",
    "detection_summary(current_result[interval_df.interval_value == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise some results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(intervals_with_count['count'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = intervals_with_count[(intervals_with_count['count'] == 51)]\n",
    "start_times = intervals.start_time.unique()\n",
    "print(f\"len start times = {len(start_times)}\")\n",
    "START_IDX = 0\n",
    "start_time = start_times[START_IDX]\n",
    "print(f\"showing start time {start_time}\")\n",
    "intervals_to_plot = intervals[intervals.start_time == start_time]\n",
    "display(intervals_to_plot)\n",
    "plot_intervals(intervals_to_plot.index.get_level_values(0).unique(), 2016, start_time = start_time, context = '1D')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
