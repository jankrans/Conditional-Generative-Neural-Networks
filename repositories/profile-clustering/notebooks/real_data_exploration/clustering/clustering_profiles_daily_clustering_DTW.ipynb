{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "federal-samuel",
   "metadata": {},
   "source": [
    "# Try to cluster the days and use this clustering to cluster the profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-outdoors",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "from visualisation import *\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "alt.renderers.enable('png')\n",
    "import itertools\n",
    "import dtaidistance.dtw as dtw\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from cluster_visualisation import *\n",
    "alt.data_transformers.disable_max_rows()\n",
    "from tqdm import tqdm\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tslearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df, data_df = read_data(nrows = 200)\n",
    "# only keep the last year of each profile \n",
    "last_of_each_profile = ~data_df.index.get_level_values(0).duplicated(keep = 'last')\n",
    "data_df = data_df.loc[last_of_each_profile]\n",
    "data_df = data_df.sample(15, random_state = 2134)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_df = get_day_df(data_df)\n",
    "day_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-vancouver",
   "metadata": {},
   "source": [
    "## Use first x days of each profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-parcel",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_OF_DAYS = 100\n",
    "day_subset_df = day_df.groupby(['meterID', 'year']).sample(NB_OF_DAYS)\n",
    "# day_subset_df = day_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "distance_matrix = get_DTW_distance_matrix(day_subset_df, 4, 0)\n",
    "distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "distance_matrix = get_DTW_distance_matrix_old(day_subset_df, 4, 0)\n",
    "distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "labels, centers = cluster_KMedoids(day_subset_df, distance_matrix, nb_of_clusters = 50, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-attempt",
   "metadata": {},
   "source": [
    "## Show the clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_clustering_chart(day_subset_df, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-camcorder",
   "metadata": {},
   "source": [
    "## Calculate the clustering of profiles based on this\n",
    "The main idea is the following when calculating the distance between two profiles x and y\n",
    "you match the days and calculate the distance between the days. \n",
    "- the distance between two days that are in the same cluster is 0 \n",
    "- the distance between two days that are in different clusters is the distance between the cluster medoids\n",
    "\n",
    "This is an assignment problem! So all the matching clusters have distance 0 so we can just remove these.  \n",
    "For the rest we make a cost matrix that describes the cost of matching a day from profile 1 to profile 2 (distance between the centroids)  \n",
    "and let scipy solve the problem for us :D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_based_on_daily_clustering(profile1, profile2, labels, centers): \n",
    "    idx = pd.IndexSlice\n",
    "    # cluster labels of each profile\n",
    "    labels1 = labels.loc[idx[profile1],:].value_counts()\n",
    "    labels2 = labels.loc[idx[profile2],:].value_counts()\n",
    "\n",
    "    # put them in the same df \n",
    "    both_labels = labels1.to_frame('labels1').join(labels2.to_frame('labels2'), how = 'outer')\n",
    "\n",
    "    # remove the matches \n",
    "    both_labels = both_labels.subtract(both_labels.min(skipna = False, axis = 1), axis = 0)\n",
    "\n",
    "    # replace zero with Nan \n",
    "    both_labels = both_labels.replace({0.0:np.NaN})\n",
    "\n",
    "    # remove all rows with NaN twice \n",
    "    both_labels = both_labels.dropna(axis = 0, how = 'all')\n",
    "\n",
    "    # get the row clusters and column clusters \n",
    "    rows = both_labels['labels1'].dropna()\n",
    "    columns = both_labels['labels2'].dropna()\n",
    "\n",
    "    # preallocate the cost matrix (use pandas to keep it easy)\n",
    "    row_index = []\n",
    "    for cluster, times in rows.iteritems():\n",
    "        row_index.extend([cluster]*int(times))\n",
    "    column_index = []\n",
    "    for cluster,times in columns.iteritems(): \n",
    "        column_index.extend([cluster]*int(times))\n",
    "    cost_matrix = pd.DataFrame(index = row_index, columns = column_index, dtype = 'float')\n",
    "\n",
    "    # fill the cost matrix with DTW distances between medoids \n",
    "    for row, column in itertools.product(cost_matrix.index.unique(), cost_matrix.columns.unique()):\n",
    "        medoid1 = centers.iloc[row].to_numpy()\n",
    "        medoid2 = centers.iloc[column].to_numpy()\n",
    "        distance = dtw.distance(medoid1, medoid2, window =4, psi = 0, use_c = True)\n",
    "        cost_matrix.loc[row,column] = distance\n",
    "    cost_array = cost_matrix.to_numpy()\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_array)\n",
    "    best_cost = cost_array[row_ind, col_ind].sum()\n",
    "    return best_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_profiles = labels.index.get_level_values(0).unique()\n",
    "all_profiles\n",
    "distance_matrix = np.zeros((len(all_profiles), len(all_profiles)))\n",
    "for idx1, idx2 in itertools.combinations(range(0,len(all_profiles)), 2):\n",
    "    meterID1 = all_profiles[idx1]\n",
    "    meterID2 = all_profiles[idx2] \n",
    "    distance = similarity_based_on_daily_clustering(meterID1, meterID2, labels, centers)\n",
    "    distance_matrix[idx1, idx2] = distance \n",
    "distance_matrix = distance_matrix + distance_matrix.T\n",
    "distance_matrix = pd.DataFrame(distance_matrix, index = all_profiles, columns = all_profiles)\n",
    "distance_matrix;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# full_labels, full_centers = cluster_KMedoids(data_df, distance_matrix.to_numpy(), 5)\n",
    "full_labels = cluster_spectral(data_df, distance_matrix.to_numpy(), 8)\n",
    "full_labels.index = full_labels.index.droplevel(1)\n",
    "full_labels.to_csv('full_clustering.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_labels.value_counts().to_frame('#profiles').rename_axis(index = 'cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_clustering(data_df, full_labels.to_frame('labels'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-addition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
