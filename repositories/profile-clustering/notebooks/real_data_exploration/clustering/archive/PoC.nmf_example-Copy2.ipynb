{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC: non-negative matrix factorization\n",
    "Let's check if non-negative matrix factorization could help us, don't care about the data problems in the data for now\n",
    "\n",
    "## Some observations\n",
    "- Seems to give good results for repetitive profiles (IDX 0 for example) \n",
    "- Does not work for profiles with injection! Cannot-handle negative values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import datetime\n",
    "import random\n",
    "from sklearn.decomposition import NMF\n",
    "idx = pd.IndexSlice\n",
    "alt.data_transformers.disable_max_rows()\n",
    "from dtaidistance import clustering, dtw\n",
    "from dtaidistance.util import SeriesContainer\n",
    "from dtaidistance.clustering.kmeans import KMeans\n",
    "from dtaidistance.dtw_barycenter import dba\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this reloads code from external modules automatically if it is changed (without having to restart the kernel)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_PATH = Path('/cw/dtaiproj/ml/2020-FLAIR-VITO/profile-clustering/preprocessed/combined')\n",
    "RESULT_PATH = Path('/cw/dtaiproj/ml/2020-FLAIR-VITO/profile-clustering/error_detection')\n",
    "RESULT_PATH.mkdir(mode = 0o770, parents = True, exist_ok=True)\n",
    "result_path = RESULT_PATH / 'cumulative_value_detection.csv' \n",
    "zero_path = RESULT_PATH / 'zero_interval_is_error.csv'\n",
    "interval_path = RESULT_PATH /'intervals_with_info.csv'\n",
    "info_path = PRE_PATH/'info.csv'\n",
    "data_path = PRE_PATH/'data.csv'\n",
    "assert info_path.exists() and data_path.exists() and zero_path.exists(), 'These paths should exist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_dt_replace(series, year=None, month=None, day=None):\n",
    "    return pd.to_datetime(\n",
    "        {'year': series.year if year is None else year,\n",
    "         'month': series.month if month is None else month,\n",
    "         'day': series.day if day is None else day, \n",
    "        'hour': series.hour,\n",
    "        'minute': series.minute})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date(series): \n",
    "    return pd.to_datetime(series, format='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DTW_distance_matrix(series, window, psi): \n",
    "    series = SeriesContainer.wrap(series)\n",
    "    distance_matrix = dtw.distance_matrix_fast(series, window=window, psi=psi,compact = False)\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_timeseries_k_mediods_DTW(series, n_clusters, window, psi):\n",
    "    # from LinkageTree implementation in dtaidistance\n",
    "    series = SeriesContainer.wrap(series)\n",
    "    distance_matrix = dtw.distance_matrix_fast(series, window=window, psi=psi,compact = False)\n",
    "    # so this distance matrix is upper triangular but it needs to be a full matrix for the clusterer\n",
    "    distance_matrix[np.isinf(distance_matrix)] = 0\n",
    "    # this works because the diagonal is 0\n",
    "    full_matrix = distance_matrix + distance_matrix.T\n",
    "    clusterer = KMedoids(n_clusters, metric='precomputed', init='k-medoids++', max_iter=1000)\n",
    "    \n",
    "    clusterer.fit(full_matrix)\n",
    "    labels = clusterer.labels_\n",
    "    centers = series[clusterer.medoid_indices_]\n",
    "    return labels, centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = pd.read_csv(info_path, index_col = [0,1])\n",
    "data_df = pd.read_csv(data_path, index_col = [0,1])\n",
    "data_df.columns = pd.to_datetime(data_df.columns)\n",
    "data_df.columns.name = 'timestamp'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SOURCE = 'EandisVREG'\n",
    "YEAR = 2016\n",
    "# get the right subset based on the info df\n",
    "info16_df = info_df.loc[idx[:, 2016],:]\n",
    "info16_df = info16_df[info16_df.data_source == 'EandisVREG']\n",
    "\n",
    "# read the corresponding data profiles \n",
    "data16_df = data_df.loc[info16_df.index, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 4\n",
    "profile_to_check = data16_df.iloc[IDX].to_frame('value')\n",
    "profile_to_check['time'] = add_date(profile_to_check.index.time)\n",
    "profile_to_check['date'] = profile_to_check.index.date.astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(profile_to_check.reset_index()[['timestamp', 'value']], title = 'full profile', width = 2000, height = 200).mark_line().encode(\n",
    "    x = 'timestamp:T', \n",
    "    y = 'value:Q', \n",
    "    \n",
    ").interactive(bind_y = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_day_chart = alt.Chart(profile_to_check, title = 'All days').mark_line().encode(\n",
    "    x = 'time:T',\n",
    "    y = 'value', \n",
    "    color = 'date'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_matrix = pd.pivot_table(profile_to_check, index = 'date', columns = 'time', values = 'value').dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = SeriesContainer.wrap(profile_matrix.to_numpy())\n",
    "barycentric_average = pd.Series(dba(series,None), index = profile_matrix.columns)\n",
    "barycentric_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_day_chart = alt.Chart(barycentric_average.to_frame('value').reset_index(), title = 'barycentric average').mark_line().encode(\n",
    "    x = 'time:T', \n",
    "    y = 'value:Q'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_day_chart | average_day_chart).resolve_scale(x = 'shared', y= 'shared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = get_DTW_distance_matrix(profile_matrix.to_numpy(), 8, 0)\n",
    "detector = LocalOutlierFactor(n_neighbors = 20, metric = 'precomputed', contamination = 0.50)\n",
    "labels = detector.fit_predict(distance_matrix)\n",
    "anomaly_labels = pd.Series(labels == -1, index = profile_matrix.index, name = 'anomaly')\n",
    "profile_vis_cluster = profile_matrix.stack().to_frame('value').join(anomaly_labels).reset_index()\n",
    "profile_vis_cluster.time = add_date(profile_vis_cluster.time)\n",
    "alt.Chart(profile_vis_cluster.reset_index()).mark_line().encode(\n",
    "    x = 'time:T', \n",
    "    y = 'value', \n",
    "    color = 'date'\n",
    ").facet(row = 'anomaly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster using kmedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_OF_CLUSTERS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# non_anomalies = profile_matrix[~anomaly_labels]\n",
    "non_anomalies = profile_matrix\n",
    "labels, centers = cluster_timeseries_k_mediods_DTW(non_anomalies.to_numpy(), NB_OF_CLUSTERS, 8, 0)\n",
    "labels = pd.Series(labels, index = non_anomalies.index, name = 'labels')\n",
    "centers = pd.DataFrame(centers, columns = non_anomalies.columns)\n",
    "centers_vis = centers.stack().to_frame('value').reset_index()\n",
    "profile_vis_cluster = non_anomalies.stack().to_frame('value').join(labels).reset_index()\n",
    "profile_vis_cluster.time = add_date(profile_vis_cluster.time)\n",
    "\n",
    "medoid_chart = alt.Chart(centers_vis).mark_line().encode(\n",
    "    x = 'time:T', \n",
    "    y = 'value', \n",
    "    color = 'level_0:N'\n",
    ")\n",
    "alt.Chart(profile_vis_cluster.reset_index()).mark_line().encode(\n",
    "    x = 'time:T', \n",
    "    y = 'value', \n",
    "    color = 'date'\n",
    ").facet(column = 'labels') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster using kmeans and barycentric averaging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_anomalies = profile_matrix[~anomaly_labels]\n",
    "non_anomalies = profile_matrix\n",
    "series = SeriesContainer.wrap(non_anomalies.to_numpy())\n",
    "model = KMeans(k=NB_OF_CLUSTERS, max_it=10, max_dba_it=10, dists_options={\"window\": 8,'psi':0})\n",
    "label_dict, performed_it = model.fit(series, use_c=True, use_parallel=True)\n",
    "\n",
    "\n",
    "labels = pd.Series(index = non_anomalies.index, name = 'labels')\n",
    "for key,value in label_dict.items(): \n",
    "    labels.iloc[list(value)] = key\n",
    "profile_vis_cluster = non_anomalies.stack().to_frame('value').join(labels).reset_index()\n",
    "profile_vis_cluster.time = add_date(profile_vis_cluster.time)\n",
    "alt.Chart(profile_vis_cluster.reset_index()).mark_line().encode(\n",
    "    x = 'time:T', \n",
    "    y = 'value', \n",
    "    color = 'date'\n",
    ").facet(column = 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = pd.DataFrame(model.means, columns = add_date(non_anomalies.columns))\n",
    "centroid_vis = centroids.stack().to_frame('value').reset_index()\n",
    "bary_chart = alt.Chart(centroid_vis).mark_line().encode(\n",
    "    x = 'time:T', \n",
    "    y= 'value:Q', \n",
    "    color = 'level_0:O'\n",
    ")\n",
    "bary_chart.properties(title = 'barycenter') | medoid_chart.properties(title = 'medoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decompose using NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# transformed_centers = centers.apply(lambda x: x - np.min(x), axis = 1, raw = True)\n",
    "matrix = profile_matrix[~anomaly_labels].to_numpy()\n",
    "# matrix = transformed_centers.to_numpy()\n",
    "# alpha controls regularization (pushing weights towards 0 such that representations become sparse)\n",
    "decomposer = NMF(8, max_iter = 10000, alpha = 0.1, l1_ratio = 1, regularization = 'both').fit(matrix)\n",
    "print('reconstruction error', decomposer.reconstruction_err_)\n",
    "components = decomposer.components_\n",
    "components_df = pd.DataFrame(components, columns = profile_matrix.columns)\n",
    "components_df.index.name = 'component_nb'\n",
    "components_df;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformed_centers_vis = transformed_centers.stack().to_frame('value').reset_index()\n",
    "\n",
    "component_vis = components_df.stack().to_frame('value').reset_index()\n",
    "component_vis['time'] = pd.to_datetime(component_vis['time'], format='%H:%M:%S')\n",
    "component_vis\n",
    "\n",
    "medoid_chart = alt.Chart(transformed_centers_vis).mark_line().encode(\n",
    "    x = 'time:T', \n",
    "    y = 'value', \n",
    "    color = 'level_0:N'\n",
    ")\n",
    "alt.Chart(component_vis, title = 'first 5 components').mark_line().encode(\n",
    "    x = 'time:T', \n",
    "    y = 'value:Q', \n",
    "    color= 'component_nb:N'\n",
    ") | medoid_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_matrix = pd.DataFrame(decomposer.transform(matrix)).sort_index()\n",
    "representation_matrix[0:62].style.background_gradient(cmap = 'Blues', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show reconstruction + used components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 12\n",
    "transformed = decomposer.transform(transformed_centers.iloc[[IDX]].to_numpy())\n",
    "original = decomposer.inverse_transform(transformed)\n",
    "day = transformed_centers.iloc[IDX].to_frame('original_value')\n",
    "day['after_reconstruction'] = original[0]\n",
    "day = day.stack().reset_index()\n",
    "day.columns = ['time', 'type', 'value']\n",
    "day.time = add_date(day.time)\n",
    "print(transformed)\n",
    "orig_chart = alt.Chart(day).mark_line().encode(\n",
    "    x = 'time:T', \n",
    "    y = 'value:Q', \n",
    "    color = 'type:N'\n",
    ")\n",
    "\n",
    "vis_df = components_df.stack().to_frame('value').reset_index()\n",
    "vis_df['weight'] = transformed[0, vis_df.component_nb]\n",
    "vis_df.time = add_date(vis_df.time)\n",
    "vis_df = vis_df[vis_df.weight > 0]\n",
    "vis_df['value'] = vis_df['value']*vis_df['weight']\n",
    "vis_df\n",
    "\n",
    "component_chart = alt.Chart(vis_df).mark_line().encode(\n",
    "    x = 'time:T', \n",
    "    y = 'value', \n",
    "    size  = 'weight',\n",
    "    opacity = 'weight',\n",
    "    color = 'component_nb:N'\n",
    ")\n",
    "\n",
    "orig_chart + component_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the reconstruction vs real profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 8\n",
    "transformed = decomposer.transform(centers.iloc[[IDX]].to_numpy())\n",
    "original = decomposer.inverse_transform(transformed)\n",
    "day = centers.iloc[IDX].to_frame('original_value')\n",
    "day['after_reconstruction'] = original[0]\n",
    "day = day.stack().reset_index()\n",
    "day.columns = ['time', 'type', 'value']\n",
    "day.time = add_date(day.time)\n",
    "print(transformed)\n",
    "alt.Chart(day).mark_line().encode(\n",
    "    x = 'time:T', \n",
    "    y = 'value:Q', \n",
    "    color = 'type:N'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
