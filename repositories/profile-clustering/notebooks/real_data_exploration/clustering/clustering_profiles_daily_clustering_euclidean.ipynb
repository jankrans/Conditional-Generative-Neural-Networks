{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "optimum-graph",
   "metadata": {},
   "source": [
    "# Try to cluster the days and use this clustering to cluster the profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "from visualisation import *\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "alt.renderers.enable('png')\n",
    "import itertools\n",
    "import dtaidistance.dtw as dtw\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from cluster_visualisation import *\n",
    "from profile_similarity import *\n",
    "alt.data_transformers.disable_max_rows()\n",
    "from tqdm import tqdm\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-share",
   "metadata": {},
   "source": [
    "## Read the data and subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "info_df, data_df = read_data_pickle()\n",
    "data_df = data_df.sort_index()\n",
    "# only keep the last year of each profile \n",
    "last_of_each_profile = ~data_df.index.get_level_values(0).duplicated(keep = 'last')\n",
    "data_df = data_df.loc[last_of_each_profile]\n",
    "# data_df = data_df.sample(20, random_state = 2134)\n",
    "print(f\"There are {len(data_df)} profiles\")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-julian",
   "metadata": {},
   "source": [
    "## Transform the data in a useable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_df = get_day_df(data_df)\n",
    "day_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-placement",
   "metadata": {},
   "source": [
    "## Idea: do outlier detection first \n",
    "The idea is that these outliers are pretty much assigned to random clusters, it is better that they are not assigned to any clusters! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-context",
   "metadata": {},
   "source": [
    "## Cluster the days \n",
    "*Note: there is quite a significant difference between kmedoids and kmeans! ARI only 0.39*  \n",
    "- k-means gives more attention to the average behavior (base usage) because the peaks kind of average out \n",
    "- k-medoids seems to care more about distinguishing feateres and not about the rest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_OF_CLUSTERS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "labels_kmedoids, centers_kmedoids = cluster_KMedoids(day_df, nb_of_clusters = NB_OF_CLUSTERS, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "labels_kmeans, centers_kmeans = cluster_KMeans(day_df, nb_of_clusters = NB_OF_CLUSTERS, random_state = 10)\n",
    "centers_kmeans = get_medoids_per_cluster(labels_kmeans, day_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(labels_kmedoids.to_numpy(), labels_kmeans.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-magazine",
   "metadata": {},
   "source": [
    "## Show the clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# daily_clustering_chart(day_subset_df, labels_kmedoids);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# daily_clustering_chart(day_subset_df, labels_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-representation",
   "metadata": {},
   "source": [
    "## Calculate the DTW distances between the medoids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "labels_to_use, medoids_to_use = labels_kmedoids, centers_kmedoids \n",
    "medoid_distances = get_DTW_distance_matrix(centers_kmedoids.to_numpy(), window = 6, psi = 0, njobs = 4)\n",
    "medoid_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-century",
   "metadata": {},
   "source": [
    "## Calculate the distance matrix based on a matching problem\n",
    "The main idea is the following when calculating the distance between two profiles x and y\n",
    "you match the days and calculate the distance between the days. \n",
    "- the distance between two days that are in the same cluster is 0 \n",
    "- the distance between two days that are in different clusters is the distance between the cluster medoids\n",
    "\n",
    "This is an assignment problem! So all the matching clusters have distance 0 so we can just remove these.  \n",
    "For the rest we make a cost matrix that describes the cost of matching a day from profile 1 to profile 2 (distance between the centroids)  \n",
    "and let scipy solve the problem for us :D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "distance_matrix = profile_distance_matrix_based_on_daily_clustering(labels_to_use, medoid_distances)\n",
    "distance_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-binary",
   "metadata": {},
   "source": [
    "## Cluster the profiles based on this distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "full_labels, full_centers = cluster_KMedoids(data_df,30 , distance_matrix.to_numpy(), random_state = 1435)\n",
    "# full_labels = cluster_spectral(data_df, distance_matrix.to_numpy(), 50)\n",
    "full_labels.index = full_labels.index.droplevel(1)\n",
    "full_labels.to_csv('04_28_full_clustering.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_labels = pd.read_csv('04_22_full_clustering.csv')\n",
    "# full_labels = full_labels.set_index('meterID').labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-former",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_count = full_labels.value_counts().to_frame('#profiles').rename_axis(index = 'cluster')\n",
    "big_clusters = cluster_count[cluster_count['#profiles'] > 1].index\n",
    "alt.Chart(cluster_count.reset_index()).mark_bar().encode(\n",
    "    x = 'cluster:N', \n",
    "    y = '#profiles'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-microwave",
   "metadata": {},
   "source": [
    "## Show the clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for distances between medoids \n",
    "medoid_meters = full_centers.index.get_level_values(0).unique()\n",
    "for idx1, idx2 in itertools.combinations(range(0,len(medoid_meters)), 2):\n",
    "    day1_plot = all_day_plot(medoid_meters[idx1], data_df)\n",
    "    day2_plot = all_day_plot(medoid_meters[idx2], data_df)\n",
    "    distance = distance_matrix.loc[medoid_meters[idx1], medoid_meters[idx2]]\n",
    "    chart = (day1_plot | day2_plot).resolve_scale(y='shared').properties(title = f\"distance = {distance}\")\n",
    "    chart.save(f'pictures/cluster_{idx1}_with_cluster_{idx2}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for distances within cluster \n",
    "for cluster_idx in range(0, len(medoid_meters)):\n",
    "    profiles_in_cluster = full_labels[full_labels == cluster_idx].index.unique()\n",
    "    medoid = medoid_meters[cluster_idx]\n",
    "    for profile in profiles_in_cluster:\n",
    "        day1_plot = all_day_plot(medoid, data_df)\n",
    "        day2_plot = all_day_plot(profile, data_df)\n",
    "        distance = distance_matrix.loc[medoid, profile]\n",
    "        chart = (day1_plot | day2_plot).resolve_scale(y='shared').properties(title = f\"distance = {distance}\")\n",
    "        chart.save(f'pictures/cluster_{cluster_idx}_with_profile_{profile}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_clustering(data_df, full_labels.to_frame('labels'), max_shown_instances = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_clustering(data_df, full_labels[full_labels.isin(big_clusters)].to_frame('labels'), max_shown_instances = 4, type = 'heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-adrian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
